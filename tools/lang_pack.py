#!/usr/bin/env python3
"""
lang_pack.py - Complete TGSpeechBox Language Pack Parser

AUTO-GENERATED by generate_lang_pack.py from pack.h + pack.cpp.
Do not edit the LanguagePack dataclass or _merge_settings() by hand.
Re-run generate_lang_pack.py to sync with C++ changes.

Hand-maintained sections are marked with "# --- MANUAL ---".

Usage:
    from lang_pack import load_pack_set, PackSet
    pack = load_pack_set("/path/to/packs", "en-us")
    print(pack.lang.coarticulation_strength)
"""

from __future__ import annotations
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional

# Use our lenient YAML parser that handles unquoted IPA symbols
from simple_yaml import load_yaml_file, get_bool, get_number, get_string

# =============================================================================
# Constants (auto-generated from pack.h FieldId enum)
# =============================================================================

FRAME_FIELD_COUNT = 47

FIELD_NAMES = [
    "voicePitch", "vibratoPitchOffset", "vibratoSpeed", "voiceTurbulenceAmplitude", "glottalOpenQuotient", "voiceAmplitude", "aspirationAmplitude", "cf1", "cf2", "cf3", "cf4", "cf5", "cf6", "cfN0", "cfNP", "cb1", "cb2", "cb3", "cb4", "cb5", "cb6", "cbN0", "cbNP", "caNP", "fricationAmplitude", "pf1", "pf2", "pf3", "pf4", "pf5", "pf6", "pb1", "pb2", "pb3", "pb4", "pb5", "pb6", "pa1", "pa2", "pa3", "pa4", "pa5", "pa6", "parallelBypass", "preFormantGain", "outputGain", "endVoicePitch",
]

FIELD_ID = {name: idx for idx, name in enumerate(FIELD_NAMES)}

PHONEME_FLAGS = {
    "_isAfricate": 1 << 0,
    "_isLiquid": 1 << 1,
    "_isNasal": 1 << 2,
    "_isSemivowel": 1 << 3,
    "_isStop": 1 << 4,
    "_isTap": 1 << 5,
    "_isTrill": 1 << 6,
    "_isVoiced": 1 << 7,
    "_isVowel": 1 << 8,
    "_copyAdjacent": 1 << 9,
}


# =============================================================================
# Data Classes — structural types (hand-maintained)
# --- MANUAL ---
# =============================================================================

@dataclass
class PhonemeDef:
    """Phoneme definition from phonemes.yaml"""
    key: str
    flags: int = 0
    set_mask: int = 0
    fields: List[float] = field(default_factory=lambda: [0.0] * FRAME_FIELD_COUNT)

    # FrameEx per-phoneme overrides
    has_creakiness: bool = False
    has_breathiness: bool = False
    has_jitter: bool = False
    has_shimmer: bool = False
    has_sharpness: bool = False
    has_end_cf1: bool = False
    has_end_cf2: bool = False
    has_end_cf3: bool = False
    has_end_pf1: bool = False
    has_end_pf2: bool = False
    has_end_pf3: bool = False
    creakiness: float = 0.0
    breathiness: float = 0.0
    jitter: float = 0.0
    shimmer: float = 0.0
    sharpness: float = 1.0
    end_cf1: float = float('nan')
    end_cf2: float = float('nan')
    end_cf3: float = float('nan')
    end_pf1: float = float('nan')
    end_pf2: float = float('nan')
    end_pf3: float = float('nan')

    @property
    def is_vowel(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isVowel"])
    @property
    def is_voiced(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isVoiced"])
    @property
    def is_stop(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isStop"])
    @property
    def is_affricate(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isAfricate"])
    @property
    def is_nasal(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isNasal"])
    @property
    def is_liquid(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isLiquid"])
    @property
    def is_semivowel(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isSemivowel"])
    @property
    def is_tap(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isTap"])
    @property
    def is_trill(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isTrill"])
    @property
    def copy_adjacent(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_copyAdjacent"])

    def get_field(self, name: str) -> float:
        idx = FIELD_ID.get(name)
        return self.fields[idx] if idx is not None else 0.0

    def has_field(self, name: str) -> bool:
        idx = FIELD_ID.get(name)
        return bool(self.set_mask & (1 << idx)) if idx is not None else False


@dataclass
class RuleWhen:
    at_word_start: bool = False
    at_word_end: bool = False
    before_class: str = ""
    after_class: str = ""
    not_before_class: str = ""
    not_after_class: str = ""


@dataclass
class ReplacementRule:
    from_str: str
    to_list: List[str]
    when: RuleWhen = field(default_factory=RuleWhen)


@dataclass
class TransformRule:
    is_vowel: int = -1
    is_voiced: int = -1
    is_stop: int = -1
    is_affricate: int = -1
    is_nasal: int = -1
    is_liquid: int = -1
    is_semivowel: int = -1
    is_tap: int = -1
    is_trill: int = -1
    is_fricative_like: int = -1
    set_ops: Dict[int, float] = field(default_factory=dict)
    scale_ops: Dict[int, float] = field(default_factory=dict)
    add_ops: Dict[int, float] = field(default_factory=dict)


@dataclass
class IntonationClause:
    pre_head_start: int = 46
    pre_head_end: int = 57
    head_extend_from: int = 4
    head_start: int = 80
    head_end: int = 50
    head_steps: List[int] = field(default_factory=lambda: [100, 75, 50, 25, 0, 63, 38, 13, 0])
    head_stress_end_delta: int = -16
    head_unstressed_run_start_delta: int = -8
    head_unstressed_run_end_delta: int = -5
    nucleus0_start: int = 64
    nucleus0_end: int = 8
    nucleus_start: int = 70
    nucleus_end: int = 18
    tail_start: int = 24
    tail_end: int = 8


# =============================================================================
# LanguagePack dataclass (auto-generated from pack.h LanguagePack struct)
# =============================================================================

def _default_traj_rates() -> List[float]:
    """Default trajectoryLimitMaxHzPerMs array (matches pack.h lambda init)."""
    a = [0.0] * FRAME_FIELD_COUNT
    a[FIELD_ID["cf2"]] = 18.0
    a[FIELD_ID["cf3"]] = 22.0
    return a


@dataclass
class LanguagePack:
    """Complete language pack — auto-generated from pack.h LanguagePack struct."""
    lang_tag: str = ""

    primary_stress_div: float = 1.4
    secondary_stress_div: float = 1.1
    voice_profile_name: str = ""
    default_vowel_duration_ms: float = 60.0
    default_fade_ms: float = 10.0
    post_stop_aspiration_duration_ms: float = 20.0
    stop_duration_ms: float = 6.0
    affricate_duration_ms: float = 24.0
    voiceless_fricative_duration_ms: float = 45.0
    voiced_consonant_duration_ms: float = 30.0
    tap_duration_ms: float = 14.0
    trill_fallback_duration_ms: float = 40.0
    nasal_min_duration_ms: float = 18.0
    tied_vowel_duration_ms: float = 40.0
    tied_from_vowel_duration_ms: float = 20.0
    tied_from_vowel_fade_ms: float = 20.0
    vowel_before_liquid_duration_ms: float = 30.0
    vowel_before_nasal_duration_ms: float = 40.0
    fade_after_liquid_ms: float = 25.0
    liquid_fade_ms: float = 20.0
    legacy_pitch_mode: str = 'espeak_style'
    legacy_pitch_inflection_scale: float = 0.58
    fujisaki_phrase_amp: float = 0.24
    fujisaki_primary_accent_amp: float = 0.24
    fujisaki_secondary_accent_amp: float = 0.12
    fujisaki_accent_mode: str = 'all'
    fujisaki_phrase_len: float = 0.0
    fujisaki_accent_len: float = 0.0
    fujisaki_accent_dur: float = 0.0
    fujisaki_declination_rate: float = 0.0003
    fujisaki_phrase_decay: float = 0.75
    fujisaki_declination_scale: float = 25.0
    fujisaki_declination_max: float = 1.25
    fujisaki_declination_post_floor: float = 0.15
    post_stop_aspiration_enabled: bool = False
    post_stop_aspiration_phoneme: str = 'h'
    stop_closure_mode: str = 'vowel-and-cluster'
    stop_closure_cluster_gaps_enabled: bool = True
    stop_closure_after_nasals_enabled: bool = False
    stop_closure_vowel_gap_ms: float = 41.0
    stop_closure_vowel_fade_ms: float = 10.0
    stop_closure_cluster_gap_ms: float = 22.0
    stop_closure_cluster_fade_ms: float = 4.0
    stop_closure_word_boundary_cluster_gap_ms: float = 0.0
    stop_closure_word_boundary_cluster_fade_ms: float = 0.0
    segment_boundary_gap_ms: float = 0.0
    segment_boundary_fade_ms: float = 0.0
    segment_boundary_skip_vowel_to_vowel: bool = True
    segment_boundary_skip_vowel_to_liquid: bool = False
    single_word_tuning_enabled: bool = False
    single_word_final_hold_ms: float = 0.0
    single_word_final_liquid_hold_scale: float = 1.0
    single_word_final_fade_ms: float = 0.0
    clause_final_fade_ms: float = 0.0
    single_word_clause_type_override: str = ''
    single_word_clause_type_override_comma_only: bool = True
    auto_tie_diphthongs: bool = False
    auto_diphthong_offglide_to_semivowel: bool = False
    semivowel_offglide_scale: float = 1.0
    trill_modulation_ms: float = 0.0
    trill_modulation_fade_ms: float = 0.0
    stressed_vowel_hiatus_gap_ms: float = 0.0
    stressed_vowel_hiatus_fade_ms: float = 0.0
    spelling_diphthong_mode: str = 'none'
    lengthened_scale: float = 1.05
    length_contrast_enabled: bool = False
    length_contrast_short_vowel_ceiling_ms: float = 80.0
    length_contrast_long_vowel_floor_ms: float = 120.0
    length_contrast_geminate_closure_scale: float = 1.8
    length_contrast_geminate_release_scale: float = 0.9
    length_contrast_pre_geminate_vowel_scale: float = 0.85
    diphthong_collapse_enabled: bool = True
    diphthong_amplitude_dip_factor: float = 0.03
    diphthong_micro_frame_interval_ms: float = 6.0
    diphthong_duration_floor_ms: float = 50.0
    diphthong_onset_hold_exponent: float = 1.4
    lengthened_scale_hu: float = 1.3
    apply_lengthened_scale_to_vowels_only: bool = True
    lengthened_vowel_final_coda_scale: float = 1.0
    coarticulation_enabled: bool = True
    coarticulation_strength: float = 0.25
    coarticulation_word_initial_fade_scale: float = 1.0
    coarticulation_graduated: bool = True
    coarticulation_adjacency_max_consonants: float = 2.0
    coarticulation_labial_f2_locus: float = 800.0
    coarticulation_alveolar_f2_locus: float = 1800.0
    coarticulation_velar_f2_locus: float = 1200.0
    coarticulation_velar_f2_locus_front: float = 0.0
    coarticulation_velar_f2_locus_back: float = 0.0
    coarticulation_mitalk_k: float = 0.42
    coarticulation_f1_scale: float = 0.6
    coarticulation_f2_scale: float = 1.0
    coarticulation_f3_scale: float = 0.5
    coarticulation_labial_scale: float = 0.5
    coarticulation_alveolar_scale: float = 1.0
    coarticulation_palatal_scale: float = 1.0
    coarticulation_velar_scale: float = 1.0
    coarticulation_aspiration_blend_start: float = 0.3
    coarticulation_aspiration_blend_end: float = 0.7
    coarticulation_velar_pinch_enabled: bool = True
    coarticulation_velar_pinch_threshold: float = 1800.0
    coarticulation_velar_pinch_f2_scale: float = 0.9
    coarticulation_velar_pinch_f3: float = 2400.0
    coarticulation_cross_syllable_scale: float = 0.70
    special_coarticulation_enabled: bool = False
    special_coartic_max_delta_hz: float = 400.0
    cluster_timing_enabled: bool = False
    cluster_timing_fric_before_stop_scale: float = 0.65
    cluster_timing_stop_before_fric_scale: float = 0.70
    cluster_timing_fric_before_fric_scale: float = 0.75
    cluster_timing_stop_before_stop_scale: float = 0.60
    cluster_timing_triple_cluster_middle_scale: float = 0.55
    cluster_timing_word_medial_consonant_scale: float = 0.85
    cluster_timing_word_final_obstruent_scale: float = 0.90
    cluster_timing_affricate_in_cluster_scale: float = 0.75
    syllable_duration_enabled: bool = False
    syllable_duration_onset_scale: float = 1.10
    syllable_duration_coda_scale: float = 0.85
    syllable_duration_unstressed_open_nucleus_scale: float = 0.80
    cluster_blend_enabled: bool = False
    cluster_blend_strength: float = 0.35
    cluster_blend_nasal_to_stop_scale: float = 1.30
    cluster_blend_fric_to_stop_scale: float = 0.85
    cluster_blend_stop_to_fric_scale: float = 0.70
    cluster_blend_nasal_to_fric_scale: float = 1.00
    cluster_blend_liquid_to_stop_scale: float = 0.85
    cluster_blend_liquid_to_fric_scale: float = 0.75
    cluster_blend_fric_to_fric_scale: float = 0.60
    cluster_blend_stop_to_stop_scale: float = 0.55
    cluster_blend_default_pair_scale: float = 0.50
    cluster_blend_homorganic_scale: float = 0.30
    cluster_blend_word_boundary_scale: float = 0.50
    cluster_blend_f1_scale: float = 0.50
    cluster_blend_forward_drift_strength: float = 0.0
    boundary_smoothing_enabled: bool = False
    boundary_smoothing_f1_scale: float = 0.3
    boundary_smoothing_f2_scale: float = 0.5
    boundary_smoothing_f3_scale: float = 0.5
    boundary_smoothing_labial_f1_scale: float = 0.25
    boundary_smoothing_labial_f2_scale: float = 0.60
    boundary_smoothing_labial_f3_scale: float = 0.55
    boundary_smoothing_alveolar_f1_scale: float = 0.30
    boundary_smoothing_alveolar_f2_scale: float = 0.40
    boundary_smoothing_alveolar_f3_scale: float = 0.35
    boundary_smoothing_palatal_f1_scale: float = 0.30
    boundary_smoothing_palatal_f2_scale: float = 0.55
    boundary_smoothing_palatal_f3_scale: float = 0.70
    boundary_smoothing_velar_f1_scale: float = 0.30
    boundary_smoothing_velar_f2_scale: float = 0.65
    boundary_smoothing_velar_f3_scale: float = 0.60
    boundary_smoothing_within_syllable_scale: float = 1.5
    boundary_smoothing_within_syllable_fade_scale: float = 1.3
    boundary_smoothing_vowel_to_stop_ms: float = 22.0
    boundary_smoothing_stop_to_vowel_ms: float = 20.0
    boundary_smoothing_vowel_to_fric_ms: float = 18.0
    boundary_smoothing_fric_to_vowel_ms: float = 18.0
    boundary_smoothing_vowel_to_nasal_ms: float = 16.0
    boundary_smoothing_nasal_to_vowel_ms: float = 16.0
    boundary_smoothing_vowel_to_liquid_ms: float = 14.0
    boundary_smoothing_liquid_to_vowel_ms: float = 14.0
    boundary_smoothing_nasal_to_stop_ms: float = 12.0
    boundary_smoothing_liquid_to_stop_ms: float = 12.0
    boundary_smoothing_fric_to_stop_ms: float = 10.0
    boundary_smoothing_stop_to_fric_ms: float = 14.0
    boundary_smoothing_vowel_to_vowel_ms: float = 18.0
    boundary_smoothing_plosive_spans_phone: bool = True
    boundary_smoothing_nasal_f1_instant: bool = True
    boundary_smoothing_nasal_f2_f3_spans_phone: bool = True
    trajectory_limit_enabled: bool = False
    trajectory_limit_apply_mask: int = (1 << 8) | (1 << 9)  # cf2 | cf3
    trajectory_limit_window_ms: float = 25.0
    trajectory_limit_apply_across_word_boundary: bool = False
    trajectory_limit_liquid_rate_scale: float = 1.5
    liquid_dynamics_enabled: bool = False
    liquid_dynamics_lateral_onglide_f1_delta: float = -50.0
    liquid_dynamics_lateral_onglide_f2_delta: float = 200.0
    liquid_dynamics_lateral_onglide_duration_pct: float = 0.30
    liquid_dynamics_rhotic_f3_dip_enabled: bool = False
    liquid_dynamics_rhotic_f3_minimum: float = 1600.0
    liquid_dynamics_rhotic_f3_dip_duration_pct: float = 0.50
    liquid_dynamics_labial_glide_transition_enabled: bool = False
    liquid_dynamics_labial_glide_start_f1: float = 300.0
    liquid_dynamics_labial_glide_start_f2: float = 700.0
    liquid_dynamics_labial_glide_transition_pct: float = 0.60
    phrase_final_lengthening_enabled: bool = False
    phrase_final_lengthening_final_syllable_scale: float = 1.4
    phrase_final_lengthening_penultimate_syllable_scale: float = 1.15
    phrase_final_lengthening_statement_scale: float = 1.0
    phrase_final_lengthening_question_scale: float = 0.9
    phrase_final_lengthening_nucleus_only_mode: bool = True
    phrase_final_lengthening_nucleus_scale: float = 0.0
    phrase_final_lengthening_nucleus_diphthong_scale: float = 0.0
    phrase_final_lengthening_coda_scale: float = 0.0
    phrase_final_lengthening_coda_stop_scale: float = 0.0
    phrase_final_lengthening_coda_fricative_scale: float = 0.0
    phrase_final_lengthening_coda_nasal_scale: float = 0.0
    prominence_enabled: bool = False
    prominence_secondary_stress_level: float = 0.6
    prominence_long_vowel_weight: float = 0.5
    prominence_long_vowel_mode: str = 'unstressed-only'
    prominence_word_initial_boost: float = 0.0
    prominence_word_final_reduction: float = 0.0
    prominence_primary_stress_weight: float = 1.4
    prominence_secondary_stress_weight: float = 1.1
    prominence_duration_prominent_floor_ms: float = 0.0
    prominence_duration_reduced_ceiling: float = 1.0
    prominence_amplitude_boost_db: float = 0.0
    prominence_amplitude_reduction_db: float = 0.0
    prominence_pitch_from_prominence: bool = False
    microprosody_enabled: bool = False
    microprosody_voiceless_f0_raise_enabled: bool = True
    microprosody_voiceless_f0_raise_hz: float = 15.0
    microprosody_voiceless_f0_raise_end_hz: float = 0.0
    microprosody_voiced_f0_lower_enabled: bool = True
    microprosody_voiced_f0_lower_hz: float = 8.0
    microprosody_min_vowel_ms: float = 25.0
    microprosody_following_f0_enabled: bool = True
    microprosody_following_voiceless_raise_hz: float = 10.0
    microprosody_following_voiced_lower_hz: float = 5.0
    microprosody_voiced_fricative_lower_scale: float = 0.6
    microprosody_intrinsic_f0_enabled: bool = True
    microprosody_intrinsic_f0_high_threshold: float = 400.0
    microprosody_intrinsic_f0_low_threshold: float = 600.0
    microprosody_intrinsic_f0_high_raise_hz: float = 6.0
    microprosody_intrinsic_f0_low_drop_hz: float = 4.0
    microprosody_pre_voiceless_shorten_enabled: bool = True
    microprosody_pre_voiceless_shorten_scale: float = 0.85
    microprosody_pre_voiceless_min_ms: float = 25.0
    microprosody_voiceless_coda_lengthen_enabled: bool = False
    microprosody_voiceless_coda_lengthen_scale: float = 1.20
    microprosody_max_total_delta_hz: float = 0.0
    rate_comp_enabled: bool = False
    rate_comp_vowel_floor_ms: float = 25.0
    rate_comp_fricative_floor_ms: float = 18.0
    rate_comp_stop_floor_ms: float = 4.0
    rate_comp_nasal_floor_ms: float = 18.0
    rate_comp_liquid_floor_ms: float = 15.0
    rate_comp_affricate_floor_ms: float = 12.0
    rate_comp_semivowel_floor_ms: float = 10.0
    rate_comp_tap_floor_ms: float = 4.0
    rate_comp_trill_floor_ms: float = 12.0
    rate_comp_voiced_consonant_floor_ms: float = 10.0
    rate_comp_word_final_bonus_ms: float = 5.0
    rate_comp_floor_speed_scale: float = 0.0
    rate_comp_cluster_proportion_guard: bool = True
    rate_comp_cluster_max_ratio_shift: float = 0.4
    rate_comp_schwa_reduction_enabled: bool = False
    rate_comp_schwa_threshold: float = 2.5
    rate_comp_schwa_scale: float = 0.8
    word_final_schwa_reduction_enabled: bool = False
    word_final_schwa_scale: float = 0.6
    word_final_schwa_min_duration_ms: float = 8.0
    nasalization_anticipatory_enabled: bool = False
    nasalization_anticipatory_amplitude: float = 0.4
    nasalization_anticipatory_blend: float = 0.5
    allophone_rules_enabled: bool = False
    hu_short_a_vowel_enabled: bool = True
    hu_short_a_vowel_key: str = 'ᴒ'
    hu_short_a_vowel_scale: float = 0.85
    english_long_u_shorten_enabled: bool = True
    english_long_u_key: str = 'u'
    english_long_u_word_final_scale: float = 0.80
    default_pre_formant_gain: float = 1.0
    default_output_gain: float = 1.5
    default_vibrato_pitch_offset: float = 0.0
    default_vibrato_speed: float = 0.0
    default_voice_turbulence_amplitude: float = 0.0
    default_glottal_open_quotient: float = 0.0
    strip_allophone_digits: bool = True
    strip_hyphen: bool = True
    tonal: bool = False
    tone_digits_enabled: bool = True
    tone_contours_absolute: bool = True
    trajectory_limit_max_hz_per_ms: List[float] = field(default_factory=lambda: _default_traj_rates())

    # --- MANUAL: complex collection types not auto-generated ---
    aliases: Dict[str, str] = field(default_factory=dict)
    pre_replacements: List[ReplacementRule] = field(default_factory=list)
    replacements: List[ReplacementRule] = field(default_factory=list)
    classes: Dict[str, List[str]] = field(default_factory=dict)
    transforms: List[TransformRule] = field(default_factory=list)
    intonation: Dict[str, IntonationClause] = field(default_factory=dict)
    tone_contours: Dict[str, List[int]] = field(default_factory=dict)


@dataclass
class PackSet:
    """Top-level pack container."""
    phonemes: Dict[str, PhonemeDef] = field(default_factory=dict)
    lang: LanguagePack = field(default_factory=LanguagePack)

    def get_phoneme(self, key: str) -> Optional[PhonemeDef]:
        return self.phonemes.get(key)


# =============================================================================
# Parsing helpers
# --- MANUAL ---
# =============================================================================

def _parse_bool(val) -> bool:
    if isinstance(val, bool):
        return val
    if isinstance(val, str):
        return val.lower() in ("true", "yes", "on", "1")
    return bool(val)


def _parse_phoneme(key: str, data: dict) -> PhonemeDef:
    """Parse a single phoneme definition from YAML dict."""
    pdef = PhonemeDef(key=key)

    for field_name, val in data.items():
        # Flags
        if field_name.startswith("_"):
            yaml_key = field_name
            if yaml_key in PHONEME_FLAGS:
                if _parse_bool(val):
                    pdef.flags |= PHONEME_FLAGS[yaml_key]
            continue

        # FrameEx block
        if field_name == "frameEx" and isinstance(val, dict):
            fx_map = {
                "creakiness": ("has_creakiness", "creakiness"),
                "breathiness": ("has_breathiness", "breathiness"),
                "jitter": ("has_jitter", "jitter"),
                "shimmer": ("has_shimmer", "shimmer"),
                "sharpness": ("has_sharpness", "sharpness"),
                "endCf1": ("has_end_cf1", "end_cf1"),
                "endCf2": ("has_end_cf2", "end_cf2"),
                "endCf3": ("has_end_cf3", "end_cf3"),
                "endPf1": ("has_end_pf1", "end_pf1"),
                "endPf2": ("has_end_pf2", "end_pf2"),
                "endPf3": ("has_end_pf3", "end_pf3"),
            }
            for fx_key, (has_attr, val_attr) in fx_map.items():
                if fx_key in val:
                    try:
                        setattr(pdef, has_attr, True)
                        setattr(pdef, val_attr, float(val[fx_key]))
                    except (ValueError, TypeError):
                        pass
            continue

        # Frame fields
        if field_name in FIELD_ID:
            try:
                idx = FIELD_ID[field_name]
                pdef.fields[idx] = float(val)
                pdef.set_mask |= (1 << idx)
            except (ValueError, TypeError):
                pass

    return pdef


def _parse_intonation(data: dict) -> IntonationClause:
    """Parse an intonation clause from YAML."""
    ic = IntonationClause()
    def gi(k, d):
        v = data.get(k)
        return int(v) if v is not None else d

    ic.pre_head_start = gi("preHeadStart", ic.pre_head_start)
    ic.pre_head_end = gi("preHeadEnd", ic.pre_head_end)
    ic.head_extend_from = gi("headExtendFrom", ic.head_extend_from)
    ic.head_start = gi("headStart", ic.head_start)
    ic.head_end = gi("headEnd", ic.head_end)
    ic.head_stress_end_delta = gi("headStressEndDelta", ic.head_stress_end_delta)
    ic.head_unstressed_run_start_delta = gi("headUnstressedRunStartDelta", ic.head_unstressed_run_start_delta)
    ic.head_unstressed_run_end_delta = gi("headUnstressedRunEndDelta", ic.head_unstressed_run_end_delta)
    ic.nucleus0_start = gi("nucleus0Start", ic.nucleus0_start)
    ic.nucleus0_end = gi("nucleus0End", ic.nucleus0_end)
    ic.nucleus_start = gi("nucleusStart", ic.nucleus_start)
    ic.nucleus_end = gi("nucleusEnd", ic.nucleus_end)
    ic.tail_start = gi("tailStart", ic.tail_start)
    ic.tail_end = gi("tailEnd", ic.tail_end)

    if "headSteps" in data and isinstance(data["headSteps"], list):
        ic.head_steps = [int(x) for x in data["headSteps"]]

    return ic


def _parse_replacement(data: dict) -> Optional[ReplacementRule]:
    """Parse a single replacement rule."""
    from_str = data.get("from")
    to_val = data.get("to")
    if from_str is None or to_val is None:
        return None
    to_list = to_val if isinstance(to_val, list) else [str(to_val)]
    to_list = [str(x) for x in to_list]
    when = RuleWhen()
    if "when" in data and isinstance(data["when"], dict):
        w = data["when"]
        when.at_word_start = _parse_bool(w.get("atWordStart", False))
        when.at_word_end = _parse_bool(w.get("atWordEnd", False))
        when.before_class = str(w.get("beforeClass", ""))
        when.after_class = str(w.get("afterClass", ""))
        when.not_before_class = str(w.get("notBeforeClass", ""))
        when.not_after_class = str(w.get("notAfterClass", ""))
    return ReplacementRule(from_str=str(from_str), to_list=to_list, when=when)


def _parse_transform(data: dict) -> Optional[TransformRule]:
    """Parse a single transform rule."""
    tr = TransformRule()
    # Accept either top-level keys or nested 'match:' map
    match_data = data.get("match", data) if isinstance(data.get("match"), dict) else data

    flag_map = {
        "isVowel": "is_vowel", "isVoiced": "is_voiced", "isStop": "is_stop",
        "isAfricate": "is_affricate", "isNasal": "is_nasal", "isLiquid": "is_liquid",
        "isSemivowel": "is_semivowel", "isTap": "is_tap", "isTrill": "is_trill",
        "isFricativeLike": "is_fricative_like",
    }
    for yaml_key, py_attr in flag_map.items():
        if yaml_key in match_data:
            setattr(tr, py_attr, 1 if _parse_bool(match_data[yaml_key]) else 0)

    def parse_field_ops(key):
        ops = {}
        if key in data and isinstance(data[key], dict):
            for fn, v in data[key].items():
                if fn in FIELD_ID:
                    try:
                        ops[FIELD_ID[fn]] = float(v)
                    except (ValueError, TypeError):
                        pass
        return ops

    tr.set_ops = parse_field_ops("set")
    tr.scale_ops = parse_field_ops("scale")
    tr.add_ops = parse_field_ops("add")
    return tr


# =============================================================================
# Merge helpers (used by auto-generated _merge_settings)
# =============================================================================

def _gn_from(d: dict, key: str, default: float) -> float:
    """Get number from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    try:
        return float(v)
    except (ValueError, TypeError):
        return default


def _gb_from(d: dict, key: str, default: bool) -> bool:
    """Get bool from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    return _parse_bool(v)


def _gs_from(d: dict, key: str, default: str) -> str:
    """Get string from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    return str(v)


def _gsl_from(d: dict, key: str, default: List[str]) -> List[str]:
    """Get string list from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    if isinstance(v, list):
        return [str(x) for x in v]
    if isinstance(v, str):
        return [s.strip() for s in v.split(",") if s.strip()]
    return default


# =============================================================================
# Settings merge (auto-generated from pack.cpp mergeSettings)
# =============================================================================

def _merge_settings(lp: LanguagePack, s: dict):
    """Merge settings section into LanguagePack.

    Auto-generated from pack.cpp mergeSettings(). Flat keys first, then
    nested blocks.
    """
    def gn(k, d):
        v = s.get(k)
        if v is None: return d
        try: return float(v)
        except (ValueError, TypeError): return d

    def gb(k, d):
        v = s.get(k)
        if v is None: return d
        return _parse_bool(v)

    def gs(k, d):
        v = s.get(k)
        if v is None: return d
        return str(v)

    # --- Flat keys (auto-generated) ---
    lp.primary_stress_div = gn("primaryStressDiv", lp.primary_stress_div)
    lp.secondary_stress_div = gn("secondaryStressDiv", lp.secondary_stress_div)
    lp.voice_profile_name = gs("voiceProfileName", lp.voice_profile_name)
    lp.legacy_pitch_inflection_scale = gn("legacyPitchInflectionScale", lp.legacy_pitch_inflection_scale)
    lp.fujisaki_phrase_amp = gn("fujisakiPhraseAmp", lp.fujisaki_phrase_amp)
    lp.fujisaki_primary_accent_amp = gn("fujisakiPrimaryAccentAmp", lp.fujisaki_primary_accent_amp)
    lp.fujisaki_secondary_accent_amp = gn("fujisakiSecondaryAccentAmp", lp.fujisaki_secondary_accent_amp)
    lp.fujisaki_accent_mode = gs("fujisakiAccentMode", lp.fujisaki_accent_mode)
    lp.fujisaki_phrase_len = gn("fujisakiPhraseLen", lp.fujisaki_phrase_len)
    lp.fujisaki_accent_len = gn("fujisakiAccentLen", lp.fujisaki_accent_len)
    lp.fujisaki_accent_dur = gn("fujisakiAccentDur", lp.fujisaki_accent_dur)
    lp.fujisaki_declination_rate = gn("fujisakiDeclinationRate", lp.fujisaki_declination_rate)
    lp.fujisaki_phrase_decay = gn("fujisakiPhraseDecay", lp.fujisaki_phrase_decay)
    lp.fujisaki_declination_scale = gn("fujisakiDeclinationScale", lp.fujisaki_declination_scale)
    lp.fujisaki_declination_max = gn("fujisakiDeclinationMax", lp.fujisaki_declination_max)
    lp.fujisaki_declination_post_floor = gn("fujisakiDeclinationPostFloor", lp.fujisaki_declination_post_floor)
    lp.post_stop_aspiration_enabled = gb("postStopAspirationEnabled", lp.post_stop_aspiration_enabled)
    lp.stop_closure_mode = gs("stopClosureMode", lp.stop_closure_mode)
    lp.stop_closure_cluster_gaps_enabled = gb("stopClosureClusterGapsEnabled", lp.stop_closure_cluster_gaps_enabled)
    lp.stop_closure_after_nasals_enabled = gb("stopClosureAfterNasalsEnabled", lp.stop_closure_after_nasals_enabled)
    lp.stop_closure_vowel_gap_ms = gn("stopClosureVowelGapMs", lp.stop_closure_vowel_gap_ms)
    lp.stop_closure_vowel_fade_ms = gn("stopClosureVowelFadeMs", lp.stop_closure_vowel_fade_ms)
    lp.stop_closure_cluster_gap_ms = gn("stopClosureClusterGapMs", lp.stop_closure_cluster_gap_ms)
    lp.stop_closure_cluster_fade_ms = gn("stopClosureClusterFadeMs", lp.stop_closure_cluster_fade_ms)
    lp.stop_closure_word_boundary_cluster_gap_ms = gn("stopClosureWordBoundaryClusterGapMs", lp.stop_closure_word_boundary_cluster_gap_ms)
    lp.stop_closure_word_boundary_cluster_fade_ms = gn("stopClosureWordBoundaryClusterFadeMs", lp.stop_closure_word_boundary_cluster_fade_ms)
    lp.segment_boundary_gap_ms = gn("segmentBoundaryGapMs", lp.segment_boundary_gap_ms)
    lp.segment_boundary_fade_ms = gn("segmentBoundaryFadeMs", lp.segment_boundary_fade_ms)
    lp.segment_boundary_skip_vowel_to_vowel = gb("segmentBoundarySkipVowelToVowel", lp.segment_boundary_skip_vowel_to_vowel)
    lp.segment_boundary_skip_vowel_to_liquid = gb("segmentBoundarySkipVowelToLiquid", lp.segment_boundary_skip_vowel_to_liquid)
    lp.single_word_tuning_enabled = gb("singleWordTuningEnabled", lp.single_word_tuning_enabled)
    lp.single_word_final_hold_ms = gn("singleWordFinalHoldMs", lp.single_word_final_hold_ms)
    lp.single_word_final_liquid_hold_scale = gn("singleWordFinalLiquidHoldScale", lp.single_word_final_liquid_hold_scale)
    lp.single_word_final_fade_ms = gn("singleWordFinalFadeMs", lp.single_word_final_fade_ms)
    lp.clause_final_fade_ms = gn("clauseFinalFadeMs", lp.clause_final_fade_ms)
    lp.single_word_clause_type_override_comma_only = gb("singleWordClauseTypeOverrideCommaOnly", lp.single_word_clause_type_override_comma_only)
    lp.auto_tie_diphthongs = gb("autoTieDiphthongs", lp.auto_tie_diphthongs)
    lp.auto_diphthong_offglide_to_semivowel = gb("autoDiphthongOffglideToSemivowel", lp.auto_diphthong_offglide_to_semivowel)
    lp.semivowel_offglide_scale = gn("semivowelOffglideScale", lp.semivowel_offglide_scale)
    lp.trill_modulation_ms = gn("trillModulationMs", lp.trill_modulation_ms)
    lp.trill_modulation_fade_ms = gn("trillModulationFadeMs", lp.trill_modulation_fade_ms)
    lp.stressed_vowel_hiatus_gap_ms = gn("stressedVowelHiatusGapMs", lp.stressed_vowel_hiatus_gap_ms)
    lp.stressed_vowel_hiatus_fade_ms = gn("stressedVowelHiatusFadeMs", lp.stressed_vowel_hiatus_fade_ms)
    lp.lengthened_scale = gn("lengthenedScale", lp.lengthened_scale)
    lp.lengthened_scale_hu = gn("lengthenedScaleHu", lp.lengthened_scale_hu)
    lp.apply_lengthened_scale_to_vowels_only = gb("applyLengthenedScaleToVowelsOnly", lp.apply_lengthened_scale_to_vowels_only)
    lp.lengthened_vowel_final_coda_scale = gn("lengthenedVowelFinalCodaScale", lp.lengthened_vowel_final_coda_scale)
    lp.coarticulation_enabled = gb("coarticulationEnabled", lp.coarticulation_enabled)
    lp.coarticulation_strength = gn("coarticulationStrength", lp.coarticulation_strength)
    lp.coarticulation_word_initial_fade_scale = gn("coarticulationWordInitialFadeScale", lp.coarticulation_word_initial_fade_scale)
    lp.coarticulation_graduated = gb("coarticulationGraduated", lp.coarticulation_graduated)
    lp.coarticulation_adjacency_max_consonants = gn("coarticulationAdjacencyMaxConsonants", lp.coarticulation_adjacency_max_consonants)
    lp.coarticulation_labial_f2_locus = gn("coarticulationLabialF2Locus", lp.coarticulation_labial_f2_locus)
    lp.coarticulation_alveolar_f2_locus = gn("coarticulationAlveolarF2Locus", lp.coarticulation_alveolar_f2_locus)
    lp.coarticulation_velar_f2_locus = gn("coarticulationVelarF2Locus", lp.coarticulation_velar_f2_locus)
    lp.coarticulation_velar_f2_locus_front = gn("coarticulationVelarF2LocusFront", lp.coarticulation_velar_f2_locus_front)
    lp.coarticulation_velar_f2_locus_back = gn("coarticulationVelarF2LocusBack", lp.coarticulation_velar_f2_locus_back)
    lp.coarticulation_mitalk_k = gn("coarticulationMitalkK", lp.coarticulation_mitalk_k)
    lp.coarticulation_f1_scale = gn("coarticulationF1Scale", lp.coarticulation_f1_scale)
    lp.coarticulation_f2_scale = gn("coarticulationF2Scale", lp.coarticulation_f2_scale)
    lp.coarticulation_f3_scale = gn("coarticulationF3Scale", lp.coarticulation_f3_scale)
    lp.coarticulation_labial_scale = gn("coarticulationLabialScale", lp.coarticulation_labial_scale)
    lp.coarticulation_alveolar_scale = gn("coarticulationAlveolarScale", lp.coarticulation_alveolar_scale)
    lp.coarticulation_palatal_scale = gn("coarticulationPalatalScale", lp.coarticulation_palatal_scale)
    lp.coarticulation_velar_scale = gn("coarticulationVelarScale", lp.coarticulation_velar_scale)
    lp.coarticulation_aspiration_blend_start = gn("coarticulationAspirationBlendStart", lp.coarticulation_aspiration_blend_start)
    lp.coarticulation_aspiration_blend_end = gn("coarticulationAspirationBlendEnd", lp.coarticulation_aspiration_blend_end)
    lp.coarticulation_velar_pinch_enabled = gb("coarticulationVelarPinchEnabled", lp.coarticulation_velar_pinch_enabled)
    lp.coarticulation_velar_pinch_threshold = gn("coarticulationVelarPinchThreshold", lp.coarticulation_velar_pinch_threshold)
    lp.coarticulation_velar_pinch_f2_scale = gn("coarticulationVelarPinchF2Scale", lp.coarticulation_velar_pinch_f2_scale)
    lp.coarticulation_velar_pinch_f3 = gn("coarticulationVelarPinchF3", lp.coarticulation_velar_pinch_f3)
    lp.coarticulation_cross_syllable_scale = gn("coarticulationCrossSyllableScale", lp.coarticulation_cross_syllable_scale)
    lp.special_coarticulation_enabled = gb("specialCoarticulationEnabled", lp.special_coarticulation_enabled)
    lp.special_coartic_max_delta_hz = gn("specialCoarticMaxDeltaHz", lp.special_coartic_max_delta_hz)
    lp.cluster_timing_enabled = gb("clusterTimingEnabled", lp.cluster_timing_enabled)
    lp.cluster_timing_fric_before_stop_scale = gn("clusterTimingFricBeforeStopScale", lp.cluster_timing_fric_before_stop_scale)
    lp.cluster_timing_stop_before_fric_scale = gn("clusterTimingStopBeforeFricScale", lp.cluster_timing_stop_before_fric_scale)
    lp.cluster_timing_fric_before_fric_scale = gn("clusterTimingFricBeforeFricScale", lp.cluster_timing_fric_before_fric_scale)
    lp.cluster_timing_stop_before_stop_scale = gn("clusterTimingStopBeforeStopScale", lp.cluster_timing_stop_before_stop_scale)
    lp.cluster_timing_triple_cluster_middle_scale = gn("clusterTimingTripleClusterMiddleScale", lp.cluster_timing_triple_cluster_middle_scale)
    lp.cluster_timing_word_medial_consonant_scale = gn("clusterTimingWordMedialConsonantScale", lp.cluster_timing_word_medial_consonant_scale)
    lp.cluster_timing_word_final_obstruent_scale = gn("clusterTimingWordFinalObstruentScale", lp.cluster_timing_word_final_obstruent_scale)
    lp.cluster_timing_affricate_in_cluster_scale = gn("clusterTimingAffricateInClusterScale", lp.cluster_timing_affricate_in_cluster_scale)
    lp.syllable_duration_enabled = gb("syllableDurationEnabled", lp.syllable_duration_enabled)
    lp.syllable_duration_onset_scale = gn("syllableDurationOnsetScale", lp.syllable_duration_onset_scale)
    lp.syllable_duration_coda_scale = gn("syllableDurationCodaScale", lp.syllable_duration_coda_scale)
    lp.syllable_duration_unstressed_open_nucleus_scale = gn("syllableDurationUnstressedOpenNucleusScale", lp.syllable_duration_unstressed_open_nucleus_scale)
    lp.cluster_blend_enabled = gb("clusterBlendEnabled", lp.cluster_blend_enabled)
    lp.cluster_blend_strength = gn("clusterBlendStrength", lp.cluster_blend_strength)
    lp.cluster_blend_nasal_to_stop_scale = gn("clusterBlendNasalToStopScale", lp.cluster_blend_nasal_to_stop_scale)
    lp.cluster_blend_fric_to_stop_scale = gn("clusterBlendFricToStopScale", lp.cluster_blend_fric_to_stop_scale)
    lp.cluster_blend_stop_to_fric_scale = gn("clusterBlendStopToFricScale", lp.cluster_blend_stop_to_fric_scale)
    lp.cluster_blend_nasal_to_fric_scale = gn("clusterBlendNasalToFricScale", lp.cluster_blend_nasal_to_fric_scale)
    lp.cluster_blend_liquid_to_stop_scale = gn("clusterBlendLiquidToStopScale", lp.cluster_blend_liquid_to_stop_scale)
    lp.cluster_blend_liquid_to_fric_scale = gn("clusterBlendLiquidToFricScale", lp.cluster_blend_liquid_to_fric_scale)
    lp.cluster_blend_fric_to_fric_scale = gn("clusterBlendFricToFricScale", lp.cluster_blend_fric_to_fric_scale)
    lp.cluster_blend_stop_to_stop_scale = gn("clusterBlendStopToStopScale", lp.cluster_blend_stop_to_stop_scale)
    lp.cluster_blend_default_pair_scale = gn("clusterBlendDefaultPairScale", lp.cluster_blend_default_pair_scale)
    lp.cluster_blend_homorganic_scale = gn("clusterBlendHomorganicScale", lp.cluster_blend_homorganic_scale)
    lp.cluster_blend_word_boundary_scale = gn("clusterBlendWordBoundaryScale", lp.cluster_blend_word_boundary_scale)
    lp.cluster_blend_f1_scale = gn("clusterBlendF1Scale", lp.cluster_blend_f1_scale)
    lp.cluster_blend_forward_drift_strength = gn("clusterBlendForwardDriftStrength", lp.cluster_blend_forward_drift_strength)
    lp.boundary_smoothing_enabled = gb("boundarySmoothingEnabled", lp.boundary_smoothing_enabled)
    lp.boundary_smoothing_f1_scale = gn("boundarySmoothingF1Scale", lp.boundary_smoothing_f1_scale)
    lp.boundary_smoothing_f2_scale = gn("boundarySmoothingF2Scale", lp.boundary_smoothing_f2_scale)
    lp.boundary_smoothing_f3_scale = gn("boundarySmoothingF3Scale", lp.boundary_smoothing_f3_scale)
    lp.boundary_smoothing_plosive_spans_phone = gb("boundarySmoothingPlosiveSpansPhone", lp.boundary_smoothing_plosive_spans_phone)
    lp.boundary_smoothing_nasal_f1_instant = gb("boundarySmoothingNasalF1Instant", lp.boundary_smoothing_nasal_f1_instant)
    lp.boundary_smoothing_nasal_f2_f3_spans_phone = gb("boundarySmoothingNasalF2F3SpansPhone", lp.boundary_smoothing_nasal_f2_f3_spans_phone)
    lp.boundary_smoothing_vowel_to_stop_ms = gn("boundarySmoothingVowelToStopFadeMs", lp.boundary_smoothing_vowel_to_stop_ms)
    lp.boundary_smoothing_stop_to_vowel_ms = gn("boundarySmoothingStopToVowelFadeMs", lp.boundary_smoothing_stop_to_vowel_ms)
    lp.boundary_smoothing_vowel_to_fric_ms = gn("boundarySmoothingVowelToFricFadeMs", lp.boundary_smoothing_vowel_to_fric_ms)
    lp.boundary_smoothing_fric_to_vowel_ms = gn("boundarySmoothingFricToVowelFadeMs", lp.boundary_smoothing_fric_to_vowel_ms)
    lp.boundary_smoothing_vowel_to_nasal_ms = gn("boundarySmoothingVowelToNasalFadeMs", lp.boundary_smoothing_vowel_to_nasal_ms)
    lp.boundary_smoothing_nasal_to_vowel_ms = gn("boundarySmoothingNasalToVowelFadeMs", lp.boundary_smoothing_nasal_to_vowel_ms)
    lp.boundary_smoothing_vowel_to_liquid_ms = gn("boundarySmoothingVowelToLiquidFadeMs", lp.boundary_smoothing_vowel_to_liquid_ms)
    lp.boundary_smoothing_liquid_to_vowel_ms = gn("boundarySmoothingLiquidToVowelFadeMs", lp.boundary_smoothing_liquid_to_vowel_ms)
    lp.boundary_smoothing_nasal_to_stop_ms = gn("boundarySmoothingNasalToStopFadeMs", lp.boundary_smoothing_nasal_to_stop_ms)
    lp.boundary_smoothing_liquid_to_stop_ms = gn("boundarySmoothingLiquidToStopFadeMs", lp.boundary_smoothing_liquid_to_stop_ms)
    lp.boundary_smoothing_fric_to_stop_ms = gn("boundarySmoothingFricToStopFadeMs", lp.boundary_smoothing_fric_to_stop_ms)
    lp.boundary_smoothing_stop_to_fric_ms = gn("boundarySmoothingStopToFricFadeMs", lp.boundary_smoothing_stop_to_fric_ms)
    lp.boundary_smoothing_vowel_to_vowel_ms = gn("boundarySmoothingVowelToVowelFadeMs", lp.boundary_smoothing_vowel_to_vowel_ms)
    lp.boundary_smoothing_labial_f1_scale = gn("boundarySmoothingLabialF1Scale", lp.boundary_smoothing_labial_f1_scale)
    lp.boundary_smoothing_labial_f2_scale = gn("boundarySmoothingLabialF2Scale", lp.boundary_smoothing_labial_f2_scale)
    lp.boundary_smoothing_labial_f3_scale = gn("boundarySmoothingLabialF3Scale", lp.boundary_smoothing_labial_f3_scale)
    lp.boundary_smoothing_alveolar_f1_scale = gn("boundarySmoothingAlveolarF1Scale", lp.boundary_smoothing_alveolar_f1_scale)
    lp.boundary_smoothing_alveolar_f2_scale = gn("boundarySmoothingAlveolarF2Scale", lp.boundary_smoothing_alveolar_f2_scale)
    lp.boundary_smoothing_alveolar_f3_scale = gn("boundarySmoothingAlveolarF3Scale", lp.boundary_smoothing_alveolar_f3_scale)
    lp.boundary_smoothing_palatal_f1_scale = gn("boundarySmoothingPalatalF1Scale", lp.boundary_smoothing_palatal_f1_scale)
    lp.boundary_smoothing_palatal_f2_scale = gn("boundarySmoothingPalatalF2Scale", lp.boundary_smoothing_palatal_f2_scale)
    lp.boundary_smoothing_palatal_f3_scale = gn("boundarySmoothingPalatalF3Scale", lp.boundary_smoothing_palatal_f3_scale)
    lp.boundary_smoothing_velar_f1_scale = gn("boundarySmoothingVelarF1Scale", lp.boundary_smoothing_velar_f1_scale)
    lp.boundary_smoothing_velar_f2_scale = gn("boundarySmoothingVelarF2Scale", lp.boundary_smoothing_velar_f2_scale)
    lp.boundary_smoothing_velar_f3_scale = gn("boundarySmoothingVelarF3Scale", lp.boundary_smoothing_velar_f3_scale)
    lp.boundary_smoothing_within_syllable_scale = gn("boundarySmoothingWithinSyllableScale", lp.boundary_smoothing_within_syllable_scale)
    lp.boundary_smoothing_within_syllable_fade_scale = gn("boundarySmoothingWithinSyllableFadeScale", lp.boundary_smoothing_within_syllable_fade_scale)
    lp.trajectory_limit_enabled = gb("trajectoryLimitEnabled", lp.trajectory_limit_enabled)
    lp.trajectory_limit_window_ms = gn("trajectoryLimitWindowMs", lp.trajectory_limit_window_ms)
    lp.trajectory_limit_apply_across_word_boundary = gb("trajectoryLimitApplyAcrossWordBoundary", lp.trajectory_limit_apply_across_word_boundary)
    lp.trajectory_limit_liquid_rate_scale = gn("trajectoryLimitLiquidRateScale", lp.trajectory_limit_liquid_rate_scale)
    lp.liquid_dynamics_enabled = gb("liquidDynamicsEnabled", lp.liquid_dynamics_enabled)
    lp.liquid_dynamics_lateral_onglide_f1_delta = gn("liquidDynamicsLateralOnglideF1Delta", lp.liquid_dynamics_lateral_onglide_f1_delta)
    lp.liquid_dynamics_lateral_onglide_f2_delta = gn("liquidDynamicsLateralOnglideF2Delta", lp.liquid_dynamics_lateral_onglide_f2_delta)
    lp.liquid_dynamics_lateral_onglide_duration_pct = gn("liquidDynamicsLateralOnglideDurationPct", lp.liquid_dynamics_lateral_onglide_duration_pct)
    lp.liquid_dynamics_rhotic_f3_dip_enabled = gb("liquidDynamicsRhoticF3DipEnabled", lp.liquid_dynamics_rhotic_f3_dip_enabled)
    lp.liquid_dynamics_rhotic_f3_minimum = gn("liquidDynamicsRhoticF3Minimum", lp.liquid_dynamics_rhotic_f3_minimum)
    lp.liquid_dynamics_rhotic_f3_dip_duration_pct = gn("liquidDynamicsRhoticF3DipDurationPct", lp.liquid_dynamics_rhotic_f3_dip_duration_pct)
    lp.liquid_dynamics_labial_glide_transition_enabled = gb("liquidDynamicsLabialGlideTransitionEnabled", lp.liquid_dynamics_labial_glide_transition_enabled)
    lp.liquid_dynamics_labial_glide_start_f1 = gn("liquidDynamicsLabialGlideStartF1", lp.liquid_dynamics_labial_glide_start_f1)
    lp.liquid_dynamics_labial_glide_start_f2 = gn("liquidDynamicsLabialGlideStartF2", lp.liquid_dynamics_labial_glide_start_f2)
    lp.liquid_dynamics_labial_glide_transition_pct = gn("liquidDynamicsLabialGlideTransitionPct", lp.liquid_dynamics_labial_glide_transition_pct)
    lp.phrase_final_lengthening_enabled = gb("phraseFinalLengtheningEnabled", lp.phrase_final_lengthening_enabled)
    lp.phrase_final_lengthening_final_syllable_scale = gn("phraseFinalLengtheningFinalSyllableScale", lp.phrase_final_lengthening_final_syllable_scale)
    lp.phrase_final_lengthening_penultimate_syllable_scale = gn("phraseFinalLengtheningPenultimateSyllableScale", lp.phrase_final_lengthening_penultimate_syllable_scale)
    lp.phrase_final_lengthening_statement_scale = gn("phraseFinalLengtheningStatementScale", lp.phrase_final_lengthening_statement_scale)
    lp.phrase_final_lengthening_question_scale = gn("phraseFinalLengtheningQuestionScale", lp.phrase_final_lengthening_question_scale)
    lp.phrase_final_lengthening_nucleus_only_mode = gb("phraseFinalLengtheningNucleusOnlyMode", lp.phrase_final_lengthening_nucleus_only_mode)
    lp.phrase_final_lengthening_nucleus_scale = gn("phraseFinalLengtheningNucleusScale", lp.phrase_final_lengthening_nucleus_scale)
    lp.phrase_final_lengthening_nucleus_diphthong_scale = gn("phraseFinalLengtheningNucleusDiphthongScale", lp.phrase_final_lengthening_nucleus_diphthong_scale)
    lp.phrase_final_lengthening_coda_scale = gn("phraseFinalLengtheningCodaScale", lp.phrase_final_lengthening_coda_scale)
    lp.phrase_final_lengthening_coda_stop_scale = gn("phraseFinalLengtheningCodaStopScale", lp.phrase_final_lengthening_coda_stop_scale)
    lp.phrase_final_lengthening_coda_fricative_scale = gn("phraseFinalLengtheningCodaFricativeScale", lp.phrase_final_lengthening_coda_fricative_scale)
    lp.phrase_final_lengthening_coda_nasal_scale = gn("phraseFinalLengtheningCodaNasalScale", lp.phrase_final_lengthening_coda_nasal_scale)
    lp.prominence_enabled = gb("prominenceEnabled", lp.prominence_enabled)
    lp.prominence_primary_stress_weight = gn("prominencePrimaryStressWeight", lp.prominence_primary_stress_weight)
    lp.prominence_secondary_stress_weight = gn("prominenceSecondaryStressWeight", lp.prominence_secondary_stress_weight)
    lp.prominence_secondary_stress_level = gn("prominenceSecondaryStressLevel", lp.prominence_secondary_stress_level)
    lp.prominence_long_vowel_weight = gn("prominenceLongVowelWeight", lp.prominence_long_vowel_weight)
    lp.prominence_long_vowel_mode = gs("prominenceLongVowelMode", lp.prominence_long_vowel_mode)
    lp.prominence_word_initial_boost = gn("prominenceWordInitialBoost", lp.prominence_word_initial_boost)
    lp.prominence_word_final_reduction = gn("prominenceWordFinalReduction", lp.prominence_word_final_reduction)
    lp.prominence_duration_prominent_floor_ms = gn("prominenceDurationProminentFloorMs", lp.prominence_duration_prominent_floor_ms)
    lp.prominence_duration_reduced_ceiling = gn("prominenceDurationReducedCeiling", lp.prominence_duration_reduced_ceiling)
    lp.prominence_amplitude_boost_db = gn("prominenceAmplitudeBoostDb", lp.prominence_amplitude_boost_db)
    lp.prominence_amplitude_reduction_db = gn("prominenceAmplitudeReductionDb", lp.prominence_amplitude_reduction_db)
    lp.prominence_pitch_from_prominence = gb("prominencePitchFromProminence", lp.prominence_pitch_from_prominence)
    lp.microprosody_enabled = gb("microprosodyEnabled", lp.microprosody_enabled)
    lp.microprosody_voiceless_f0_raise_enabled = gb("microprosodyVoicelessF0RaiseEnabled", lp.microprosody_voiceless_f0_raise_enabled)
    lp.microprosody_voiceless_f0_raise_hz = gn("microprosodyVoicelessF0RaiseHz", lp.microprosody_voiceless_f0_raise_hz)
    lp.microprosody_voiceless_f0_raise_end_hz = gn("microprosodyVoicelessF0RaiseEndHz", lp.microprosody_voiceless_f0_raise_end_hz)
    lp.microprosody_voiced_f0_lower_enabled = gb("microprosodyVoicedF0LowerEnabled", lp.microprosody_voiced_f0_lower_enabled)
    lp.microprosody_voiced_f0_lower_hz = gn("microprosodyVoicedF0LowerHz", lp.microprosody_voiced_f0_lower_hz)
    lp.microprosody_min_vowel_ms = gn("microprosodyMinVowelMs", lp.microprosody_min_vowel_ms)
    lp.microprosody_following_f0_enabled = gb("microprosodyFollowingF0Enabled", lp.microprosody_following_f0_enabled)
    lp.microprosody_following_voiceless_raise_hz = gn("microprosodyFollowingVoicelessRaiseHz", lp.microprosody_following_voiceless_raise_hz)
    lp.microprosody_following_voiced_lower_hz = gn("microprosodyFollowingVoicedLowerHz", lp.microprosody_following_voiced_lower_hz)
    lp.microprosody_voiced_fricative_lower_scale = gn("microprosodyVoicedFricativeLowerScale", lp.microprosody_voiced_fricative_lower_scale)
    lp.microprosody_intrinsic_f0_enabled = gb("microprosodyIntrinsicF0Enabled", lp.microprosody_intrinsic_f0_enabled)
    lp.microprosody_intrinsic_f0_high_threshold = gn("microprosodyIntrinsicF0HighThreshold", lp.microprosody_intrinsic_f0_high_threshold)
    lp.microprosody_intrinsic_f0_low_threshold = gn("microprosodyIntrinsicF0LowThreshold", lp.microprosody_intrinsic_f0_low_threshold)
    lp.microprosody_intrinsic_f0_high_raise_hz = gn("microprosodyIntrinsicF0HighRaiseHz", lp.microprosody_intrinsic_f0_high_raise_hz)
    lp.microprosody_intrinsic_f0_low_drop_hz = gn("microprosodyIntrinsicF0LowDropHz", lp.microprosody_intrinsic_f0_low_drop_hz)
    lp.microprosody_pre_voiceless_shorten_enabled = gb("microprosodyPreVoicelessShortenEnabled", lp.microprosody_pre_voiceless_shorten_enabled)
    lp.microprosody_pre_voiceless_shorten_scale = gn("microprosodyPreVoicelessShortenScale", lp.microprosody_pre_voiceless_shorten_scale)
    lp.microprosody_pre_voiceless_min_ms = gn("microprosodyPreVoicelessMinMs", lp.microprosody_pre_voiceless_min_ms)
    lp.microprosody_voiceless_coda_lengthen_enabled = gb("microprosodyVoicelessCodaLengthenEnabled", lp.microprosody_voiceless_coda_lengthen_enabled)
    lp.microprosody_voiceless_coda_lengthen_scale = gn("microprosodyVoicelessCodaLengthenScale", lp.microprosody_voiceless_coda_lengthen_scale)
    lp.microprosody_max_total_delta_hz = gn("microprosodyMaxTotalDeltaHz", lp.microprosody_max_total_delta_hz)
    lp.nasal_min_duration_ms = gn("nasalMinDurationMs", lp.nasal_min_duration_ms)
    lp.rate_comp_enabled = gb("rateCompEnabled", lp.rate_comp_enabled)
    lp.rate_comp_vowel_floor_ms = gn("rateCompVowelFloorMs", lp.rate_comp_vowel_floor_ms)
    lp.rate_comp_fricative_floor_ms = gn("rateCompFricativeFloorMs", lp.rate_comp_fricative_floor_ms)
    lp.rate_comp_stop_floor_ms = gn("rateCompStopFloorMs", lp.rate_comp_stop_floor_ms)
    lp.rate_comp_nasal_floor_ms = gn("rateCompNasalFloorMs", lp.rate_comp_nasal_floor_ms)
    lp.rate_comp_liquid_floor_ms = gn("rateCompLiquidFloorMs", lp.rate_comp_liquid_floor_ms)
    lp.rate_comp_affricate_floor_ms = gn("rateCompAffricateFloorMs", lp.rate_comp_affricate_floor_ms)
    lp.rate_comp_semivowel_floor_ms = gn("rateCompSemivowelFloorMs", lp.rate_comp_semivowel_floor_ms)
    lp.rate_comp_tap_floor_ms = gn("rateCompTapFloorMs", lp.rate_comp_tap_floor_ms)
    lp.rate_comp_trill_floor_ms = gn("rateCompTrillFloorMs", lp.rate_comp_trill_floor_ms)
    lp.rate_comp_voiced_consonant_floor_ms = gn("rateCompVoicedConsonantFloorMs", lp.rate_comp_voiced_consonant_floor_ms)
    lp.rate_comp_word_final_bonus_ms = gn("rateCompWordFinalBonusMs", lp.rate_comp_word_final_bonus_ms)
    lp.rate_comp_floor_speed_scale = gn("rateCompFloorSpeedScale", lp.rate_comp_floor_speed_scale)
    lp.rate_comp_cluster_proportion_guard = gb("rateCompClusterProportionGuard", lp.rate_comp_cluster_proportion_guard)
    lp.rate_comp_cluster_max_ratio_shift = gn("rateCompClusterMaxRatioShift", lp.rate_comp_cluster_max_ratio_shift)
    lp.rate_comp_schwa_reduction_enabled = gb("rateCompSchwaReductionEnabled", lp.rate_comp_schwa_reduction_enabled)
    lp.rate_comp_schwa_threshold = gn("rateCompSchwaThreshold", lp.rate_comp_schwa_threshold)
    lp.rate_comp_schwa_scale = gn("rateCompSchwaScale", lp.rate_comp_schwa_scale)
    lp.word_final_schwa_reduction_enabled = gb("wordFinalSchwaReductionEnabled", lp.word_final_schwa_reduction_enabled)
    lp.word_final_schwa_scale = gn("wordFinalSchwaScale", lp.word_final_schwa_scale)
    lp.word_final_schwa_min_duration_ms = gn("wordFinalSchwaMinDurationMs", lp.word_final_schwa_min_duration_ms)
    lp.nasalization_anticipatory_enabled = gb("nasalizationAnticipatoryEnabled", lp.nasalization_anticipatory_enabled)
    lp.nasalization_anticipatory_amplitude = gn("nasalizationAnticipatoryAmplitude", lp.nasalization_anticipatory_amplitude)
    lp.nasalization_anticipatory_blend = gn("nasalizationAnticipatoryBlend", lp.nasalization_anticipatory_blend)
    lp.allophone_rules_enabled = gb("allophoneRulesEnabled", lp.allophone_rules_enabled)
    lp.length_contrast_enabled = gb("lengthContrastEnabled", lp.length_contrast_enabled)
    lp.length_contrast_short_vowel_ceiling_ms = gn("lengthContrastShortVowelCeilingMs", lp.length_contrast_short_vowel_ceiling_ms)
    lp.length_contrast_long_vowel_floor_ms = gn("lengthContrastLongVowelFloorMs", lp.length_contrast_long_vowel_floor_ms)
    lp.length_contrast_geminate_closure_scale = gn("lengthContrastGeminateClosureScale", lp.length_contrast_geminate_closure_scale)
    lp.length_contrast_geminate_release_scale = gn("lengthContrastGeminateReleaseScale", lp.length_contrast_geminate_release_scale)
    lp.length_contrast_pre_geminate_vowel_scale = gn("lengthContrastPreGeminateVowelScale", lp.length_contrast_pre_geminate_vowel_scale)
    lp.diphthong_collapse_enabled = gb("diphthongCollapseEnabled", lp.diphthong_collapse_enabled)
    lp.diphthong_amplitude_dip_factor = gn("diphthongAmplitudeDipFactor", lp.diphthong_amplitude_dip_factor)
    lp.diphthong_micro_frame_interval_ms = gn("diphthongMicroFrameIntervalMs", lp.diphthong_micro_frame_interval_ms)
    lp.diphthong_duration_floor_ms = gn("diphthongDurationFloorMs", lp.diphthong_duration_floor_ms)
    lp.diphthong_onset_hold_exponent = gn("diphthongOnsetHoldExponent", lp.diphthong_onset_hold_exponent)
    lp.hu_short_a_vowel_enabled = gb("huShortAVowelEnabled", lp.hu_short_a_vowel_enabled)
    lp.hu_short_a_vowel_scale = gn("huShortAVowelScale", lp.hu_short_a_vowel_scale)
    lp.english_long_u_shorten_enabled = gb("englishLongUShortenEnabled", lp.english_long_u_shorten_enabled)
    lp.english_long_u_word_final_scale = gn("englishLongUWordFinalScale", lp.english_long_u_word_final_scale)
    lp.default_pre_formant_gain = gn("defaultPreFormantGain", lp.default_pre_formant_gain)
    lp.default_output_gain = gn("defaultOutputGain", lp.default_output_gain)
    lp.default_vibrato_pitch_offset = gn("defaultVibratoPitchOffset", lp.default_vibrato_pitch_offset)
    lp.default_vibrato_speed = gn("defaultVibratoSpeed", lp.default_vibrato_speed)
    lp.default_voice_turbulence_amplitude = gn("defaultVoiceTurbulenceAmplitude", lp.default_voice_turbulence_amplitude)
    lp.default_glottal_open_quotient = gn("defaultGlottalOpenQuotient", lp.default_glottal_open_quotient)
    lp.strip_allophone_digits = gb("stripAllophoneDigits", lp.strip_allophone_digits)
    lp.strip_hyphen = gb("stripHyphen", lp.strip_hyphen)
    lp.tonal = gb("tonal", lp.tonal)
    lp.tone_digits_enabled = gb("toneDigitsEnabled", lp.tone_digits_enabled)
    lp.tone_contours_absolute = gb("toneContoursAbsolute", lp.tone_contours_absolute)

    # --- Special: legacyPitchMode string/bool hybrid ---
    raw = s.get("legacyPitchMode")
    if raw is not None:
        raw_str = str(raw).lower()
        if raw_str in ("true", "1"):
            lp.legacy_pitch_mode = "legacy"
        elif raw_str in ("false", "0"):
            lp.legacy_pitch_mode = "espeak_style"
        else:
            lp.legacy_pitch_mode = str(raw)

    # --- Special: postStopAspirationPhoneme (stored as plain string) ---
    v = s.get("postStopAspirationPhoneme")
    if v is not None:
        lp.post_stop_aspiration_phoneme = str(v)

    # --- Special: singleWordClauseTypeOverride (single char) ---
    v = s.get("singleWordClauseTypeOverride")
    if v is not None:
        sv = str(v)
        lp.single_word_clause_type_override = sv[0] if sv else ''

    # --- Special: spellingDiphthongMode (validated enum) ---
    v = s.get("spellingDiphthongMode")
    if v is not None:
        m = str(v).lower()
        if m in ("none", "monophthong"):
            lp.spelling_diphthong_mode = m

    # --- Special: toneContoursMode -> toneContoursAbsolute ---
    v = s.get("toneContoursMode")
    if v is not None:
        m = str(v).lower()
        if m == "relative":
            lp.tone_contours_absolute = False
        elif m == "absolute":
            lp.tone_contours_absolute = True

    # --- Special: trajectoryLimit flat-key parsing ---
    # trajectoryLimitApplyTo: "[cf2, cf3]" or "cf2, cf3"
    v = s.get("trajectoryLimitApplyTo")
    if v is not None:
        cleaned = str(v).replace("[", "").replace("]", "")
        mask = 0
        for part in cleaned.split(","):
            fn = part.strip()
            if fn in FIELD_ID:
                mask |= (1 << FIELD_ID[fn])
        if mask:
            lp.trajectory_limit_apply_mask = mask

    # trajectoryLimitMaxHzPerMs flat keys
    for suffix, fid_name in [("Cf2", "cf2"), ("Cf3", "cf3"), ("Pf2", "pf2"), ("Pf3", "pf3")]:
        v = s.get(f"trajectoryLimitMaxHzPerMs{suffix}")
        if v is not None:
            try:
                fv = float(v)
                if fv > 0.0:
                    lp.trajectory_limit_max_hz_per_ms[FIELD_ID[fid_name]] = fv
            except (ValueError, TypeError):
                pass

    # --- Nested blocks (auto-generated) ---

    if "prominence" in s and isinstance(s["prominence"], dict):
        _pr = s["prominence"]
        lp.prominence_enabled = _gb_from(_pr, "enabled", lp.prominence_enabled)
        lp.prominence_primary_stress_weight = _gn_from(_pr, "primaryStressWeight", lp.prominence_primary_stress_weight)
        lp.prominence_secondary_stress_weight = _gn_from(_pr, "secondaryStressWeight", lp.prominence_secondary_stress_weight)
        lp.prominence_secondary_stress_level = _gn_from(_pr, "secondaryStressLevel", lp.prominence_secondary_stress_level)
        lp.prominence_long_vowel_weight = _gn_from(_pr, "longVowelWeight", lp.prominence_long_vowel_weight)
        lp.prominence_long_vowel_mode = _gs_from(_pr, "longVowelMode", lp.prominence_long_vowel_mode)
        lp.prominence_word_initial_boost = _gn_from(_pr, "wordInitialBoost", lp.prominence_word_initial_boost)
        lp.prominence_word_final_reduction = _gn_from(_pr, "wordFinalReduction", lp.prominence_word_final_reduction)
        lp.prominence_duration_prominent_floor_ms = _gn_from(_pr, "durationProminentFloorMs", lp.prominence_duration_prominent_floor_ms)
        lp.prominence_duration_reduced_ceiling = _gn_from(_pr, "durationReducedCeiling", lp.prominence_duration_reduced_ceiling)
        lp.prominence_amplitude_boost_db = _gn_from(_pr, "amplitudeBoostDb", lp.prominence_amplitude_boost_db)
        lp.prominence_amplitude_reduction_db = _gn_from(_pr, "amplitudeReductionDb", lp.prominence_amplitude_reduction_db)
        lp.prominence_pitch_from_prominence = _gb_from(_pr, "pitchFromProminence", lp.prominence_pitch_from_prominence)

    if "rateCompensation" in s and isinstance(s["rateCompensation"], dict):
        _rc = s["rateCompensation"]
        lp.rate_comp_enabled = _gb_from(_rc, "enabled", lp.rate_comp_enabled)
        lp.rate_comp_word_final_bonus_ms = _gn_from(_rc, "wordFinalBonusMs", lp.rate_comp_word_final_bonus_ms)
        lp.rate_comp_floor_speed_scale = _gn_from(_rc, "floorSpeedScale", lp.rate_comp_floor_speed_scale)
        lp.rate_comp_cluster_proportion_guard = _gb_from(_rc, "clusterProportionGuard", lp.rate_comp_cluster_proportion_guard)
        lp.rate_comp_cluster_max_ratio_shift = _gn_from(_rc, "clusterMaxRatioShift", lp.rate_comp_cluster_max_ratio_shift)
        if "minimumDurations" in _rc and isinstance(_rc["minimumDurations"], dict):
            _md = _rc["minimumDurations"]
            lp.rate_comp_vowel_floor_ms = _gn_from(_md, "vowelMs", lp.rate_comp_vowel_floor_ms)
            lp.rate_comp_fricative_floor_ms = _gn_from(_md, "fricativeMs", lp.rate_comp_fricative_floor_ms)
            lp.rate_comp_stop_floor_ms = _gn_from(_md, "stopMs", lp.rate_comp_stop_floor_ms)
            lp.rate_comp_nasal_floor_ms = _gn_from(_md, "nasalMs", lp.rate_comp_nasal_floor_ms)
            lp.rate_comp_liquid_floor_ms = _gn_from(_md, "liquidMs", lp.rate_comp_liquid_floor_ms)
            lp.rate_comp_affricate_floor_ms = _gn_from(_md, "affricateMs", lp.rate_comp_affricate_floor_ms)
            lp.rate_comp_semivowel_floor_ms = _gn_from(_md, "semivowelMs", lp.rate_comp_semivowel_floor_ms)
            lp.rate_comp_tap_floor_ms = _gn_from(_md, "tapMs", lp.rate_comp_tap_floor_ms)
            lp.rate_comp_trill_floor_ms = _gn_from(_md, "trillMs", lp.rate_comp_trill_floor_ms)
            lp.rate_comp_voiced_consonant_floor_ms = _gn_from(_md, "voicedConsonantMs", lp.rate_comp_voiced_consonant_floor_ms)
        if "schwaReduction" in _rc and isinstance(_rc["schwaReduction"], dict):
            _sr = _rc["schwaReduction"]
            lp.rate_comp_schwa_reduction_enabled = _gb_from(_sr, "enabled", lp.rate_comp_schwa_reduction_enabled)
            lp.rate_comp_schwa_threshold = _gn_from(_sr, "threshold", lp.rate_comp_schwa_threshold)
            lp.rate_comp_schwa_scale = _gn_from(_sr, "scale", lp.rate_comp_schwa_scale)

    if "boundarySmoothing" in s and isinstance(s["boundarySmoothing"], dict):
        _bs = s["boundarySmoothing"]
        lp.boundary_smoothing_enabled = _gb_from(_bs, "enabled", lp.boundary_smoothing_enabled)
        lp.boundary_smoothing_f1_scale = _gn_from(_bs, "f1Scale", lp.boundary_smoothing_f1_scale)
        lp.boundary_smoothing_f2_scale = _gn_from(_bs, "f2Scale", lp.boundary_smoothing_f2_scale)
        lp.boundary_smoothing_f3_scale = _gn_from(_bs, "f3Scale", lp.boundary_smoothing_f3_scale)
        lp.boundary_smoothing_plosive_spans_phone = _gb_from(_bs, "plosiveSpansPhone", lp.boundary_smoothing_plosive_spans_phone)
        lp.boundary_smoothing_nasal_f1_instant = _gb_from(_bs, "nasalF1Instant", lp.boundary_smoothing_nasal_f1_instant)
        lp.boundary_smoothing_nasal_f2_f3_spans_phone = _gb_from(_bs, "nasalF2F3SpansPhone", lp.boundary_smoothing_nasal_f2_f3_spans_phone)
        lp.boundary_smoothing_vowel_to_stop_ms = _gn_from(_bs, "vowelToStopFadeMs", lp.boundary_smoothing_vowel_to_stop_ms)
        lp.boundary_smoothing_stop_to_vowel_ms = _gn_from(_bs, "stopToVowelFadeMs", lp.boundary_smoothing_stop_to_vowel_ms)
        lp.boundary_smoothing_vowel_to_fric_ms = _gn_from(_bs, "vowelToFricFadeMs", lp.boundary_smoothing_vowel_to_fric_ms)
        lp.boundary_smoothing_fric_to_vowel_ms = _gn_from(_bs, "fricToVowelFadeMs", lp.boundary_smoothing_fric_to_vowel_ms)
        lp.boundary_smoothing_vowel_to_nasal_ms = _gn_from(_bs, "vowelToNasalFadeMs", lp.boundary_smoothing_vowel_to_nasal_ms)
        lp.boundary_smoothing_nasal_to_vowel_ms = _gn_from(_bs, "nasalToVowelFadeMs", lp.boundary_smoothing_nasal_to_vowel_ms)
        lp.boundary_smoothing_vowel_to_liquid_ms = _gn_from(_bs, "vowelToLiquidFadeMs", lp.boundary_smoothing_vowel_to_liquid_ms)
        lp.boundary_smoothing_liquid_to_vowel_ms = _gn_from(_bs, "liquidToVowelFadeMs", lp.boundary_smoothing_liquid_to_vowel_ms)
        lp.boundary_smoothing_nasal_to_stop_ms = _gn_from(_bs, "nasalToStopFadeMs", lp.boundary_smoothing_nasal_to_stop_ms)
        lp.boundary_smoothing_liquid_to_stop_ms = _gn_from(_bs, "liquidToStopFadeMs", lp.boundary_smoothing_liquid_to_stop_ms)
        lp.boundary_smoothing_fric_to_stop_ms = _gn_from(_bs, "fricToStopFadeMs", lp.boundary_smoothing_fric_to_stop_ms)
        lp.boundary_smoothing_stop_to_fric_ms = _gn_from(_bs, "stopToFricFadeMs", lp.boundary_smoothing_stop_to_fric_ms)
        lp.boundary_smoothing_vowel_to_vowel_ms = _gn_from(_bs, "vowelToVowelFadeMs", lp.boundary_smoothing_vowel_to_vowel_ms)
        lp.boundary_smoothing_labial_f1_scale = _gn_from(_bs, "labialF1Scale", lp.boundary_smoothing_labial_f1_scale)
        lp.boundary_smoothing_labial_f2_scale = _gn_from(_bs, "labialF2Scale", lp.boundary_smoothing_labial_f2_scale)
        lp.boundary_smoothing_labial_f3_scale = _gn_from(_bs, "labialF3Scale", lp.boundary_smoothing_labial_f3_scale)
        lp.boundary_smoothing_alveolar_f1_scale = _gn_from(_bs, "alveolarF1Scale", lp.boundary_smoothing_alveolar_f1_scale)
        lp.boundary_smoothing_alveolar_f2_scale = _gn_from(_bs, "alveolarF2Scale", lp.boundary_smoothing_alveolar_f2_scale)
        lp.boundary_smoothing_alveolar_f3_scale = _gn_from(_bs, "alveolarF3Scale", lp.boundary_smoothing_alveolar_f3_scale)
        lp.boundary_smoothing_palatal_f1_scale = _gn_from(_bs, "palatalF1Scale", lp.boundary_smoothing_palatal_f1_scale)
        lp.boundary_smoothing_palatal_f2_scale = _gn_from(_bs, "palatalF2Scale", lp.boundary_smoothing_palatal_f2_scale)
        lp.boundary_smoothing_palatal_f3_scale = _gn_from(_bs, "palatalF3Scale", lp.boundary_smoothing_palatal_f3_scale)
        lp.boundary_smoothing_velar_f1_scale = _gn_from(_bs, "velarF1Scale", lp.boundary_smoothing_velar_f1_scale)
        lp.boundary_smoothing_velar_f2_scale = _gn_from(_bs, "velarF2Scale", lp.boundary_smoothing_velar_f2_scale)
        lp.boundary_smoothing_velar_f3_scale = _gn_from(_bs, "velarF3Scale", lp.boundary_smoothing_velar_f3_scale)
        lp.boundary_smoothing_within_syllable_scale = _gn_from(_bs, "withinSyllableScale", lp.boundary_smoothing_within_syllable_scale)
        lp.boundary_smoothing_within_syllable_fade_scale = _gn_from(_bs, "withinSyllableFadeScale", lp.boundary_smoothing_within_syllable_fade_scale)

    if "syllableStructure" in s and isinstance(s["syllableStructure"], dict):
        _ss = s["syllableStructure"]

    if "trajectoryLimit" in s and isinstance(s["trajectoryLimit"], dict):
        _tl = s["trajectoryLimit"]
        lp.trajectory_limit_enabled = _gb_from(_tl, "enabled", lp.trajectory_limit_enabled)
        lp.trajectory_limit_window_ms = _gn_from(_tl, "windowMs", lp.trajectory_limit_window_ms)
        lp.trajectory_limit_apply_across_word_boundary = _gb_from(_tl, "applyAcrossWordBoundary", lp.trajectory_limit_apply_across_word_boundary)
        lp.trajectory_limit_liquid_rate_scale = _gn_from(_tl, "liquidRateScale", lp.trajectory_limit_liquid_rate_scale)
        if "maxHzPerMs" in _tl and isinstance(_tl["maxHzPerMs"], dict):
            _mh = _tl["maxHzPerMs"]

    if "liquidDynamics" in s and isinstance(s["liquidDynamics"], dict):
        _ld = s["liquidDynamics"]
        lp.liquid_dynamics_enabled = _gb_from(_ld, "enabled", lp.liquid_dynamics_enabled)
        if "lateralOnglide" in _ld and isinstance(_ld["lateralOnglide"], dict):
            _lo = _ld["lateralOnglide"]
            lp.liquid_dynamics_lateral_onglide_f1_delta = _gn_from(_lo, "f1Delta", lp.liquid_dynamics_lateral_onglide_f1_delta)
            lp.liquid_dynamics_lateral_onglide_f2_delta = _gn_from(_lo, "f2Delta", lp.liquid_dynamics_lateral_onglide_f2_delta)
            lp.liquid_dynamics_lateral_onglide_duration_pct = _gn_from(_lo, "durationPct", lp.liquid_dynamics_lateral_onglide_duration_pct)
        if "rhoticF3Dip" in _ld and isinstance(_ld["rhoticF3Dip"], dict):
            _rd = _ld["rhoticF3Dip"]
            lp.liquid_dynamics_rhotic_f3_dip_enabled = _gb_from(_rd, "enabled", lp.liquid_dynamics_rhotic_f3_dip_enabled)
            lp.liquid_dynamics_rhotic_f3_minimum = _gn_from(_rd, "f3Minimum", lp.liquid_dynamics_rhotic_f3_minimum)
            lp.liquid_dynamics_rhotic_f3_dip_duration_pct = _gn_from(_rd, "dipDurationPct", lp.liquid_dynamics_rhotic_f3_dip_duration_pct)
        if "labialGlideTransition" in _ld and isinstance(_ld["labialGlideTransition"], dict):
            _wg = _ld["labialGlideTransition"]
            lp.liquid_dynamics_labial_glide_transition_enabled = _gb_from(_wg, "enabled", lp.liquid_dynamics_labial_glide_transition_enabled)
            lp.liquid_dynamics_labial_glide_start_f1 = _gn_from(_wg, "startF1", lp.liquid_dynamics_labial_glide_start_f1)
            lp.liquid_dynamics_labial_glide_start_f2 = _gn_from(_wg, "startF2", lp.liquid_dynamics_labial_glide_start_f2)
            lp.liquid_dynamics_labial_glide_transition_pct = _gn_from(_wg, "transitionPct", lp.liquid_dynamics_labial_glide_transition_pct)

    if "lengthContrast" in s and isinstance(s["lengthContrast"], dict):
        _lc = s["lengthContrast"]
        lp.length_contrast_enabled = _gb_from(_lc, "enabled", lp.length_contrast_enabled)
        lp.length_contrast_short_vowel_ceiling_ms = _gn_from(_lc, "shortVowelCeiling", lp.length_contrast_short_vowel_ceiling_ms)
        lp.length_contrast_long_vowel_floor_ms = _gn_from(_lc, "longVowelFloor", lp.length_contrast_long_vowel_floor_ms)
        lp.length_contrast_geminate_closure_scale = _gn_from(_lc, "geminateClosureScale", lp.length_contrast_geminate_closure_scale)
        lp.length_contrast_geminate_release_scale = _gn_from(_lc, "geminateReleaseScale", lp.length_contrast_geminate_release_scale)
        lp.length_contrast_pre_geminate_vowel_scale = _gn_from(_lc, "preGeminateVowelScale", lp.length_contrast_pre_geminate_vowel_scale)

    if "diphthongCollapse" in s and isinstance(s["diphthongCollapse"], dict):
        _dc = s["diphthongCollapse"]
        lp.diphthong_collapse_enabled = _gb_from(_dc, "enabled", lp.diphthong_collapse_enabled)
        lp.diphthong_amplitude_dip_factor = _gn_from(_dc, "amplitudeDipFactor", lp.diphthong_amplitude_dip_factor)
        lp.diphthong_micro_frame_interval_ms = _gn_from(_dc, "microFrameIntervalMs", lp.diphthong_micro_frame_interval_ms)
        lp.diphthong_duration_floor_ms = _gn_from(_dc, "durationFloorMs", lp.diphthong_duration_floor_ms)
        lp.diphthong_onset_hold_exponent = _gn_from(_dc, "onsetHoldExponent", lp.diphthong_onset_hold_exponent)

    if "allophoneRules" in s and isinstance(s["allophoneRules"], dict):
        _ar = s["allophoneRules"]
        lp.allophone_rules_enabled = _gb_from(_ar, "enabled", lp.allophone_rules_enabled)

    if "positionalAllophones" in s and isinstance(s["positionalAllophones"], dict):
        _pa = s["positionalAllophones"]

    if "specialCoarticulation" in s and isinstance(s["specialCoarticulation"], dict):
        _sc = s["specialCoarticulation"]
        lp.special_coarticulation_enabled = _gb_from(_sc, "enabled", lp.special_coarticulation_enabled)
        lp.special_coartic_max_delta_hz = _gn_from(_sc, "maxDeltaHz", lp.special_coartic_max_delta_hz)

    if "clusterTiming" in s and isinstance(s["clusterTiming"], dict):
        _ct = s["clusterTiming"]
        lp.cluster_timing_enabled = _gb_from(_ct, "enabled", lp.cluster_timing_enabled)
        lp.cluster_timing_fric_before_stop_scale = _gn_from(_ct, "fricBeforeStopScale", lp.cluster_timing_fric_before_stop_scale)
        lp.cluster_timing_stop_before_fric_scale = _gn_from(_ct, "stopBeforeFricScale", lp.cluster_timing_stop_before_fric_scale)
        lp.cluster_timing_fric_before_fric_scale = _gn_from(_ct, "fricBeforeFricScale", lp.cluster_timing_fric_before_fric_scale)
        lp.cluster_timing_stop_before_stop_scale = _gn_from(_ct, "stopBeforeStopScale", lp.cluster_timing_stop_before_stop_scale)
        lp.cluster_timing_triple_cluster_middle_scale = _gn_from(_ct, "tripleClusterMiddleScale", lp.cluster_timing_triple_cluster_middle_scale)
        lp.cluster_timing_affricate_in_cluster_scale = _gn_from(_ct, "affricateInClusterScale", lp.cluster_timing_affricate_in_cluster_scale)
        lp.cluster_timing_word_medial_consonant_scale = _gn_from(_ct, "wordMedialConsonantScale", lp.cluster_timing_word_medial_consonant_scale)
        lp.cluster_timing_word_final_obstruent_scale = _gn_from(_ct, "wordFinalObstruentScale", lp.cluster_timing_word_final_obstruent_scale)

    if "syllableDuration" in s and isinstance(s["syllableDuration"], dict):
        _sd = s["syllableDuration"]
        lp.syllable_duration_enabled = _gb_from(_sd, "enabled", lp.syllable_duration_enabled)
        lp.syllable_duration_onset_scale = _gn_from(_sd, "onsetScale", lp.syllable_duration_onset_scale)
        lp.syllable_duration_coda_scale = _gn_from(_sd, "codaScale", lp.syllable_duration_coda_scale)
        lp.syllable_duration_unstressed_open_nucleus_scale = _gn_from(_sd, "unstressedOpenNucleusScale", lp.syllable_duration_unstressed_open_nucleus_scale)

    if "clusterBlend" in s and isinstance(s["clusterBlend"], dict):
        _cb = s["clusterBlend"]
        lp.cluster_blend_enabled = _gb_from(_cb, "enabled", lp.cluster_blend_enabled)
        lp.cluster_blend_strength = _gn_from(_cb, "strength", lp.cluster_blend_strength)
        lp.cluster_blend_nasal_to_stop_scale = _gn_from(_cb, "nasalToStopScale", lp.cluster_blend_nasal_to_stop_scale)
        lp.cluster_blend_fric_to_stop_scale = _gn_from(_cb, "fricToStopScale", lp.cluster_blend_fric_to_stop_scale)
        lp.cluster_blend_stop_to_fric_scale = _gn_from(_cb, "stopToFricScale", lp.cluster_blend_stop_to_fric_scale)
        lp.cluster_blend_nasal_to_fric_scale = _gn_from(_cb, "nasalToFricScale", lp.cluster_blend_nasal_to_fric_scale)
        lp.cluster_blend_liquid_to_stop_scale = _gn_from(_cb, "liquidToStopScale", lp.cluster_blend_liquid_to_stop_scale)
        lp.cluster_blend_liquid_to_fric_scale = _gn_from(_cb, "liquidToFricScale", lp.cluster_blend_liquid_to_fric_scale)
        lp.cluster_blend_fric_to_fric_scale = _gn_from(_cb, "fricToFricScale", lp.cluster_blend_fric_to_fric_scale)
        lp.cluster_blend_stop_to_stop_scale = _gn_from(_cb, "stopToStopScale", lp.cluster_blend_stop_to_stop_scale)
        lp.cluster_blend_default_pair_scale = _gn_from(_cb, "defaultPairScale", lp.cluster_blend_default_pair_scale)
        lp.cluster_blend_homorganic_scale = _gn_from(_cb, "homorganicScale", lp.cluster_blend_homorganic_scale)
        lp.cluster_blend_word_boundary_scale = _gn_from(_cb, "wordBoundaryScale", lp.cluster_blend_word_boundary_scale)
        lp.cluster_blend_f1_scale = _gn_from(_cb, "f1Scale", lp.cluster_blend_f1_scale)
        lp.cluster_blend_forward_drift_strength = _gn_from(_cb, "forwardDriftStrength", lp.cluster_blend_forward_drift_strength)

    # --- Special nested: trajectoryLimit maxHzPerMs map + applyTo list ---
    if "trajectoryLimit" in s and isinstance(s["trajectoryLimit"], dict):
        _tl = s["trajectoryLimit"]
        if "applyTo" in _tl and isinstance(_tl["applyTo"], list):
            mask = 0
            for fn in _tl["applyTo"]:
                if str(fn) in FIELD_ID:
                    mask |= (1 << FIELD_ID[str(fn)])
            if mask:
                lp.trajectory_limit_apply_mask = mask
        if "maxHzPerMs" in _tl and isinstance(_tl["maxHzPerMs"], dict):
            for fn, v in _tl["maxHzPerMs"].items():
                if fn in FIELD_ID:
                    try:
                        lp.trajectory_limit_max_hz_per_ms[FIELD_ID[fn]] = float(v)
                    except (ValueError, TypeError):
                        pass


# =============================================================================
# Normalization / Intonation / Tone merge
# --- MANUAL ---
# =============================================================================

def _merge_norm(lp: LanguagePack, n: dict):
    if "aliases" in n and isinstance(n["aliases"], dict):
        for k, v in n["aliases"].items():
            lp.aliases[str(k)] = str(v)
    if "classes" in n and isinstance(n["classes"], dict):
        for cn, items in n["classes"].items():
            if isinstance(items, list):
                lp.classes[str(cn)] = [str(x) for x in items]
    if "preReplacements" in n and isinstance(n["preReplacements"], list):
        for item in n["preReplacements"]:
            if isinstance(item, dict):
                r = _parse_replacement(item)
                if r:
                    lp.pre_replacements.append(r)
    if "replacements" in n and isinstance(n["replacements"], list):
        for item in n["replacements"]:
            if isinstance(item, dict):
                r = _parse_replacement(item)
                if r:
                    lp.replacements.append(r)
    if "stripAllophoneDigits" in n:
        lp.strip_allophone_digits = _parse_bool(n["stripAllophoneDigits"])
    if "stripHyphen" in n:
        lp.strip_hyphen = _parse_bool(n["stripHyphen"])


def _merge_intonation(lp: LanguagePack, data: dict):
    for k, v in data.items():
        if k and k[0] in ".?!," and isinstance(v, dict):
            lp.intonation[k[0]] = _parse_intonation(v)


def _merge_tones(lp: LanguagePack, data: dict):
    for k, v in data.items():
        pts = [int(x) for x in v] if isinstance(v, list) else [int(v)] if isinstance(v, (int, float)) else []
        if pts:
            lp.tone_contours[str(k)] = pts


def _merge_transforms(lp: LanguagePack, data):
    if not isinstance(data, list):
        return
    for item in data:
        if isinstance(item, dict):
            tr = _parse_transform(item)
            if tr:
                lp.transforms.append(tr)


# =============================================================================
# Default intonation (matches applyLanguageDefaults in pack.cpp)
# --- MANUAL ---
# =============================================================================

def _apply_defaults(lp: LanguagePack):
    lp.intonation["."] = IntonationClause(46,57,4,80,50,[100,75,50,25,0,63,38,13,0],-16,-8,-5,64,8,70,18,24,8)
    lp.intonation[","] = IntonationClause(46,57,4,80,60,[100,75,50,25,0,63,38,13,0],-16,-8,-5,34,52,78,34,34,52)
    lp.intonation["?"] = IntonationClause(45,56,3,75,43,[100,75,50,20,60,35,11,0],-16,-7,0,34,68,86,21,34,68)
    lp.intonation["!"] = IntonationClause(46,57,3,90,50,[100,75,50,16,82,50,32,16],-16,-9,0,92,4,92,80,76,4)


# =============================================================================
# Main loading functions
# --- MANUAL ---
# =============================================================================

def find_packs_root(pack_dir: str) -> Path:
    p = Path(pack_dir)
    if (p / "phonemes.yaml").exists():
        return p
    if (p / "packs" / "phonemes.yaml").exists():
        return p / "packs"
    raise FileNotFoundError(f"phonemes.yaml not found under {pack_dir}")


def load_pack_set(pack_dir: str, lang_tag: str = "default") -> PackSet:
    """Load complete pack set with phonemes and merged language settings."""
    root = find_packs_root(pack_dir)
    pack = PackSet()

    # Load phonemes
    data = load_yaml_file(root / "phonemes.yaml")
    if data and "phonemes" in data:
        for k, v in data["phonemes"].items():
            if isinstance(v, dict):
                pack.phonemes[k] = _parse_phoneme(k, v)

    # Initialize language pack
    pack.lang = LanguagePack()
    pack.lang.lang_tag = lang_tag.lower().replace("_", "-")
    _apply_defaults(pack.lang)

    # Build chain: default -> base -> base-region
    chain = ["default"]
    parts = pack.lang.lang_tag.split("-")
    cur = ""
    for p in parts:
        cur = f"{cur}-{p}" if cur else p
        if cur not in chain:
            chain.append(cur)

    # Load each file in chain
    for name in chain:
        lf = root / "lang" / f"{name}.yaml"
        if lf.exists():
            data = load_yaml_file(lf)
            if not data:
                continue
            if "settings" in data:
                _merge_settings(pack.lang, data["settings"])
            if "normalization" in data:
                _merge_norm(pack.lang, data["normalization"])
            if "transforms" in data:
                _merge_transforms(pack.lang, data["transforms"])
            if "intonation" in data:
                _merge_intonation(pack.lang, data["intonation"])
            if "toneContours" in data:
                _merge_tones(pack.lang, data["toneContours"])
            if "phonemes" in data:
                for k, v in data["phonemes"].items():
                    if isinstance(v, dict):
                        pack.phonemes[k] = _parse_phoneme(k, v)

    return pack


# =============================================================================
# Utilities
# --- MANUAL ---
# =============================================================================

def format_pack_summary(pack: PackSet) -> str:
    """Return a human-readable summary of the pack."""
    lp = pack.lang
    return f"""=== Pack: {lp.lang_tag} ===
Phonemes: {len(pack.phonemes)}

Timing:
  primaryStressDiv: {lp.primary_stress_div}
  secondaryStressDiv: {lp.secondary_stress_div}
  defaultVowelDurationMs: {lp.default_vowel_duration_ms}
  defaultFadeMs: {lp.default_fade_ms}
  stopDurationMs: {lp.stop_duration_ms}

Pitch:
  legacyPitchMode: {lp.legacy_pitch_mode}
  fujisakiPhraseAmp: {lp.fujisaki_phrase_amp}
  fujisakiAccentMode: {lp.fujisaki_accent_mode}

Stop Closure:
  mode: {lp.stop_closure_mode}
  vowelGapMs: {lp.stop_closure_vowel_gap_ms}
  clusterGapMs: {lp.stop_closure_cluster_gap_ms}

Coarticulation:
  enabled: {lp.coarticulation_enabled}
  strength: {lp.coarticulation_strength}
  mitalkK: {lp.coarticulation_mitalk_k}
  labialF2Locus: {lp.coarticulation_labial_f2_locus}
  alveolarF2Locus: {lp.coarticulation_alveolar_f2_locus}
  velarF2Locus: {lp.coarticulation_velar_f2_locus}

Trajectory Limiting:
  enabled: {lp.trajectory_limit_enabled}
  windowMs: {lp.trajectory_limit_window_ms}

Defaults:
  preFormantGain: {lp.default_pre_formant_gain}
  outputGain: {lp.default_output_gain}
"""


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("Usage: python lang_pack.py <packs_dir> [lang_tag]")
        sys.exit(1)
    lang = sys.argv[2] if len(sys.argv) > 2 else "default"
    pack = load_pack_set(sys.argv[1], lang)
    print(format_pack_summary(pack))
