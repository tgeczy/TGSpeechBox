#!/usr/bin/env python3
"""
lang_pack.py - Complete TGSpeechBox Language Pack Parser

AUTO-GENERATED by generate_lang_pack.py from pack.h + pack.cpp.
Do not edit the LanguagePack dataclass or _merge_settings() by hand.
Re-run generate_lang_pack.py to sync with C++ changes.

Hand-maintained sections are marked with "# --- MANUAL ---".

Usage:
    from lang_pack import load_pack_set, PackSet
    pack = load_pack_set("/path/to/packs", "en-us")
    print(pack.lang.coarticulation_strength)
"""

from __future__ import annotations
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional

# Use our lenient YAML parser that handles unquoted IPA symbols
from simple_yaml import load_yaml_file, get_bool, get_number, get_string

# =============================================================================
# Constants (auto-generated from pack.h FieldId enum)
# =============================================================================

FRAME_FIELD_COUNT = 47

FIELD_NAMES = [
    "voicePitch", "vibratoPitchOffset", "vibratoSpeed", "voiceTurbulenceAmplitude", "glottalOpenQuotient", "voiceAmplitude", "aspirationAmplitude", "cf1", "cf2", "cf3", "cf4", "cf5", "cf6", "cfN0", "cfNP", "cb1", "cb2", "cb3", "cb4", "cb5", "cb6", "cbN0", "cbNP", "caNP", "fricationAmplitude", "pf1", "pf2", "pf3", "pf4", "pf5", "pf6", "pb1", "pb2", "pb3", "pb4", "pb5", "pb6", "pa1", "pa2", "pa3", "pa4", "pa5", "pa6", "parallelBypass", "preFormantGain", "outputGain", "endVoicePitch",
]

FIELD_ID = {name: idx for idx, name in enumerate(FIELD_NAMES)}

PHONEME_FLAGS = {
    "_isAfricate": 1 << 0,
    "_isLiquid": 1 << 1,
    "_isNasal": 1 << 2,
    "_isSemivowel": 1 << 3,
    "_isStop": 1 << 4,
    "_isTap": 1 << 5,
    "_isTrill": 1 << 6,
    "_isVoiced": 1 << 7,
    "_isVowel": 1 << 8,
    "_copyAdjacent": 1 << 9,
}


# =============================================================================
# Data Classes — structural types (hand-maintained)
# --- MANUAL ---
# =============================================================================

@dataclass
class PhonemeDef:
    """Phoneme definition from phonemes.yaml"""
    key: str
    flags: int = 0
    set_mask: int = 0
    fields: List[float] = field(default_factory=lambda: [0.0] * FRAME_FIELD_COUNT)

    # FrameEx per-phoneme overrides
    has_creakiness: bool = False
    has_breathiness: bool = False
    has_jitter: bool = False
    has_shimmer: bool = False
    has_sharpness: bool = False
    has_end_cf1: bool = False
    has_end_cf2: bool = False
    has_end_cf3: bool = False
    has_end_pf1: bool = False
    has_end_pf2: bool = False
    has_end_pf3: bool = False
    creakiness: float = 0.0
    breathiness: float = 0.0
    jitter: float = 0.0
    shimmer: float = 0.0
    sharpness: float = 1.0
    end_cf1: float = float('nan')
    end_cf2: float = float('nan')
    end_cf3: float = float('nan')
    end_pf1: float = float('nan')
    end_pf2: float = float('nan')
    end_pf3: float = float('nan')

    @property
    def is_vowel(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isVowel"])
    @property
    def is_voiced(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isVoiced"])
    @property
    def is_stop(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isStop"])
    @property
    def is_affricate(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isAfricate"])
    @property
    def is_nasal(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isNasal"])
    @property
    def is_liquid(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isLiquid"])
    @property
    def is_semivowel(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isSemivowel"])
    @property
    def is_tap(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isTap"])
    @property
    def is_trill(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_isTrill"])
    @property
    def copy_adjacent(self) -> bool: return bool(self.flags & PHONEME_FLAGS["_copyAdjacent"])

    def get_field(self, name: str) -> float:
        idx = FIELD_ID.get(name)
        return self.fields[idx] if idx is not None else 0.0

    def has_field(self, name: str) -> bool:
        idx = FIELD_ID.get(name)
        return bool(self.set_mask & (1 << idx)) if idx is not None else False


@dataclass
class RuleWhen:
    at_word_start: bool = False
    at_word_end: bool = False
    before_class: str = ""
    after_class: str = ""
    not_before_class: str = ""
    not_after_class: str = ""


@dataclass
class ReplacementRule:
    from_str: str
    to_list: List[str]
    when: RuleWhen = field(default_factory=RuleWhen)


@dataclass
class TransformRule:
    is_vowel: int = -1
    is_voiced: int = -1
    is_stop: int = -1
    is_affricate: int = -1
    is_nasal: int = -1
    is_liquid: int = -1
    is_semivowel: int = -1
    is_tap: int = -1
    is_trill: int = -1
    is_fricative_like: int = -1
    set_ops: Dict[int, float] = field(default_factory=dict)
    scale_ops: Dict[int, float] = field(default_factory=dict)
    add_ops: Dict[int, float] = field(default_factory=dict)


@dataclass
class IntonationClause:
    pre_head_start: int = 46
    pre_head_end: int = 57
    head_extend_from: int = 4
    head_start: int = 80
    head_end: int = 50
    head_steps: List[int] = field(default_factory=lambda: [100, 75, 50, 25, 0, 63, 38, 13, 0])
    head_stress_end_delta: int = -16
    head_unstressed_run_start_delta: int = -8
    head_unstressed_run_end_delta: int = -5
    nucleus0_start: int = 64
    nucleus0_end: int = 8
    nucleus_start: int = 70
    nucleus_end: int = 18
    tail_start: int = 24
    tail_end: int = 8


# =============================================================================
# LanguagePack dataclass (auto-generated from pack.h LanguagePack struct)
# =============================================================================

def _default_traj_rates() -> List[float]:
    """Default trajectoryLimitMaxHzPerMs array (matches pack.h lambda init)."""
    a = [0.0] * FRAME_FIELD_COUNT
    a[FIELD_ID["cf2"]] = 18.0
    a[FIELD_ID["cf3"]] = 22.0
    return a


@dataclass
class LanguagePack:
    """Complete language pack — auto-generated from pack.h LanguagePack struct."""
    lang_tag: str = ""

    primary_stress_div: float = 1.4
    secondary_stress_div: float = 1.1
    voice_profile_name: str = ""
    default_vowel_duration_ms: float = 60.0
    default_fade_ms: float = 10.0
    post_stop_aspiration_duration_ms: float = 20.0
    stop_duration_ms: float = 6.0
    affricate_duration_ms: float = 24.0
    voiceless_fricative_duration_ms: float = 45.0
    voiced_consonant_duration_ms: float = 30.0
    tap_duration_ms: float = 14.0
    trill_fallback_duration_ms: float = 40.0
    tied_vowel_duration_ms: float = 40.0
    tied_from_vowel_duration_ms: float = 20.0
    tied_from_vowel_fade_ms: float = 20.0
    vowel_before_liquid_duration_ms: float = 30.0
    vowel_before_nasal_duration_ms: float = 40.0
    fade_after_liquid_ms: float = 25.0
    liquid_fade_ms: float = 20.0
    legacy_pitch_mode: str = 'espeak_style'
    legacy_pitch_inflection_scale: float = 0.58
    fujisaki_phrase_amp: float = 0.24
    fujisaki_primary_accent_amp: float = 0.24
    fujisaki_secondary_accent_amp: float = 0.12
    fujisaki_accent_mode: str = 'all'
    fujisaki_phrase_len: float = 0.0
    fujisaki_accent_len: float = 0.0
    fujisaki_accent_dur: float = 0.0
    fujisaki_declination_scale: float = 25.0
    fujisaki_declination_max: float = 1.25
    fujisaki_declination_post_floor: float = 0.15
    post_stop_aspiration_enabled: bool = False
    post_stop_aspiration_phoneme: str = 'h'
    stop_closure_mode: str = 'vowel-and-cluster'
    stop_closure_cluster_gaps_enabled: bool = True
    stop_closure_after_nasals_enabled: bool = False
    stop_closure_vowel_gap_ms: float = 41.0
    stop_closure_vowel_fade_ms: float = 10.0
    stop_closure_cluster_gap_ms: float = 22.0
    stop_closure_cluster_fade_ms: float = 4.0
    stop_closure_word_boundary_cluster_gap_ms: float = 0.0
    stop_closure_word_boundary_cluster_fade_ms: float = 0.0
    segment_boundary_gap_ms: float = 0.0
    segment_boundary_fade_ms: float = 0.0
    segment_boundary_skip_vowel_to_vowel: bool = True
    segment_boundary_skip_vowel_to_liquid: bool = False
    single_word_tuning_enabled: bool = False
    single_word_final_hold_ms: float = 0.0
    single_word_final_liquid_hold_scale: float = 1.0
    single_word_final_fade_ms: float = 0.0
    single_word_clause_type_override: str = ''
    single_word_clause_type_override_comma_only: bool = True
    auto_tie_diphthongs: bool = False
    auto_diphthong_offglide_to_semivowel: bool = False
    semivowel_offglide_scale: float = 1.0
    trill_modulation_ms: float = 0.0
    trill_modulation_fade_ms: float = 0.0
    stressed_vowel_hiatus_gap_ms: float = 0.0
    stressed_vowel_hiatus_fade_ms: float = 0.0
    spelling_diphthong_mode: str = 'none'
    lengthened_scale: float = 1.05
    length_contrast_enabled: bool = False
    length_contrast_short_vowel_ceiling_ms: float = 80.0
    length_contrast_long_vowel_floor_ms: float = 120.0
    length_contrast_geminate_closure_scale: float = 1.8
    length_contrast_geminate_release_scale: float = 0.9
    length_contrast_pre_geminate_vowel_scale: float = 0.85
    lengthened_scale_hu: float = 1.3
    apply_lengthened_scale_to_vowels_only: bool = True
    lengthened_vowel_final_coda_scale: float = 1.0
    coarticulation_enabled: bool = True
    coarticulation_strength: float = 0.25
    coarticulation_transition_extent: float = 0.35
    coarticulation_fade_into_consonants: bool = True
    coarticulation_word_initial_fade_scale: float = 1.0
    coarticulation_graduated: bool = True
    coarticulation_adjacency_max_consonants: float = 2.0
    coarticulation_labial_f2_locus: float = 800.0
    coarticulation_alveolar_f2_locus: float = 1800.0
    coarticulation_velar_f2_locus: float = 1200.0
    coarticulation_mitalk_k: float = 0.42
    coarticulation_f1_scale: float = 0.6
    coarticulation_f2_scale: float = 1.0
    coarticulation_f3_scale: float = 0.5
    coarticulation_alveolar_back_vowel_enabled: bool = True
    coarticulation_back_vowel_f2_threshold: float = 1400.0
    coarticulation_alveolar_back_vowel_strength_boost: float = 1.25
    coarticulation_labialized_fricative_fronting_enabled: bool = True
    coarticulation_labialized_fricative_f2_pull: float = 0.15
    coarticulation_velar_pinch_enabled: bool = True
    coarticulation_velar_pinch_threshold: float = 1800.0
    coarticulation_velar_pinch_f2_scale: float = 0.9
    coarticulation_velar_pinch_f3: float = 2400.0
    boundary_smoothing_enabled: bool = False
    boundary_smoothing_vowel_to_stop_fade_ms: float = 12.0
    boundary_smoothing_stop_to_vowel_fade_ms: float = 10.0
    boundary_smoothing_vowel_to_fric_fade_ms: float = 6.0
    trajectory_limit_enabled: bool = False
    trajectory_limit_apply_mask: int = (1 << 8) | (1 << 9)  # cf2 | cf3
    trajectory_limit_window_ms: float = 25.0
    trajectory_limit_apply_across_word_boundary: bool = False
    liquid_dynamics_enabled: bool = False
    liquid_dynamics_lateral_onglide_f1_delta: float = -50.0
    liquid_dynamics_lateral_onglide_f2_delta: float = 200.0
    liquid_dynamics_lateral_onglide_duration_pct: float = 0.30
    liquid_dynamics_rhotic_f3_dip_enabled: bool = False
    liquid_dynamics_rhotic_f3_minimum: float = 1600.0
    liquid_dynamics_rhotic_f3_dip_duration_pct: float = 0.50
    liquid_dynamics_labial_glide_transition_enabled: bool = False
    liquid_dynamics_labial_glide_start_f1: float = 300.0
    liquid_dynamics_labial_glide_start_f2: float = 700.0
    liquid_dynamics_labial_glide_transition_pct: float = 0.60
    phrase_final_lengthening_enabled: bool = False
    phrase_final_lengthening_final_syllable_scale: float = 1.4
    phrase_final_lengthening_penultimate_syllable_scale: float = 1.15
    phrase_final_lengthening_statement_scale: float = 1.0
    phrase_final_lengthening_question_scale: float = 0.9
    phrase_final_lengthening_nucleus_only_mode: bool = True
    microprosody_enabled: bool = False
    microprosody_voiceless_f0_raise_enabled: bool = True
    microprosody_voiceless_f0_raise_hz: float = 15.0
    microprosody_voiceless_f0_raise_end_hz: float = 0.0
    microprosody_voiced_f0_lower_enabled: bool = True
    microprosody_voiced_f0_lower_hz: float = 8.0
    microprosody_min_vowel_ms: float = 25.0
    rate_reduction_enabled: bool = False
    rate_reduction_schwa_reduction_threshold: float = 2.5
    rate_reduction_schwa_min_duration_ms: float = 15.0
    rate_reduction_schwa_scale: float = 0.8
    word_final_schwa_reduction_enabled: bool = False
    word_final_schwa_scale: float = 0.6
    word_final_schwa_min_duration_ms: float = 8.0
    nasalization_anticipatory_enabled: bool = False
    nasalization_anticipatory_amplitude: float = 0.4
    nasalization_anticipatory_blend: float = 0.5
    positional_allophones_enabled: bool = False
    positional_allophones_stop_aspiration_word_initial_stressed: float = 0.8
    positional_allophones_stop_aspiration_word_initial: float = 0.5
    positional_allophones_stop_aspiration_intervocalic: float = 0.2
    positional_allophones_stop_aspiration_word_final: float = 0.1
    positional_allophones_lateral_darkness_pre_vocalic: float = 0.2
    positional_allophones_lateral_darkness_post_vocalic: float = 0.8
    positional_allophones_lateral_darkness_syllabic: float = 0.9
    positional_allophones_lateral_dark_f2_target_hz: float = 900.0
    positional_allophones_glottal_reinforcement_enabled: bool = False
    positional_allophones_glottal_reinforcement_duration_ms: float = 18.0
    hu_short_a_vowel_enabled: bool = True
    hu_short_a_vowel_key: str = 'ᴒ'
    hu_short_a_vowel_scale: float = 0.85
    english_long_u_shorten_enabled: bool = True
    english_long_u_key: str = 'u'
    english_long_u_word_final_scale: float = 0.80
    default_pre_formant_gain: float = 1.0
    default_output_gain: float = 1.5
    default_vibrato_pitch_offset: float = 0.0
    default_vibrato_speed: float = 0.0
    default_voice_turbulence_amplitude: float = 0.0
    default_glottal_open_quotient: float = 0.0
    strip_allophone_digits: bool = True
    strip_hyphen: bool = True
    tonal: bool = False
    tone_digits_enabled: bool = True
    tone_contours_absolute: bool = True
    positional_allophones_glottal_reinforcement_contexts: List[str] = field(default_factory=lambda: ['V_#'])
    trajectory_limit_max_hz_per_ms: List[float] = field(default_factory=lambda: _default_traj_rates())

    # --- MANUAL: complex collection types not auto-generated ---
    aliases: Dict[str, str] = field(default_factory=dict)
    pre_replacements: List[ReplacementRule] = field(default_factory=list)
    replacements: List[ReplacementRule] = field(default_factory=list)
    classes: Dict[str, List[str]] = field(default_factory=dict)
    transforms: List[TransformRule] = field(default_factory=list)
    intonation: Dict[str, IntonationClause] = field(default_factory=dict)
    tone_contours: Dict[str, List[int]] = field(default_factory=dict)


@dataclass
class PackSet:
    """Top-level pack container."""
    phonemes: Dict[str, PhonemeDef] = field(default_factory=dict)
    lang: LanguagePack = field(default_factory=LanguagePack)

    def get_phoneme(self, key: str) -> Optional[PhonemeDef]:
        return self.phonemes.get(key)


# =============================================================================
# Parsing helpers
# --- MANUAL ---
# =============================================================================

def _parse_bool(val) -> bool:
    if isinstance(val, bool):
        return val
    if isinstance(val, str):
        return val.lower() in ("true", "yes", "on", "1")
    return bool(val)


def _parse_phoneme(key: str, data: dict) -> PhonemeDef:
    """Parse a single phoneme definition from YAML dict."""
    pdef = PhonemeDef(key=key)

    for field_name, val in data.items():
        # Flags
        if field_name.startswith("_"):
            yaml_key = field_name
            if yaml_key in PHONEME_FLAGS:
                if _parse_bool(val):
                    pdef.flags |= PHONEME_FLAGS[yaml_key]
            continue

        # FrameEx block
        if field_name == "frameEx" and isinstance(val, dict):
            fx_map = {
                "creakiness": ("has_creakiness", "creakiness"),
                "breathiness": ("has_breathiness", "breathiness"),
                "jitter": ("has_jitter", "jitter"),
                "shimmer": ("has_shimmer", "shimmer"),
                "sharpness": ("has_sharpness", "sharpness"),
                "endCf1": ("has_end_cf1", "end_cf1"),
                "endCf2": ("has_end_cf2", "end_cf2"),
                "endCf3": ("has_end_cf3", "end_cf3"),
                "endPf1": ("has_end_pf1", "end_pf1"),
                "endPf2": ("has_end_pf2", "end_pf2"),
                "endPf3": ("has_end_pf3", "end_pf3"),
            }
            for fx_key, (has_attr, val_attr) in fx_map.items():
                if fx_key in val:
                    try:
                        setattr(pdef, has_attr, True)
                        setattr(pdef, val_attr, float(val[fx_key]))
                    except (ValueError, TypeError):
                        pass
            continue

        # Frame fields
        if field_name in FIELD_ID:
            try:
                idx = FIELD_ID[field_name]
                pdef.fields[idx] = float(val)
                pdef.set_mask |= (1 << idx)
            except (ValueError, TypeError):
                pass

    return pdef


def _parse_intonation(data: dict) -> IntonationClause:
    """Parse an intonation clause from YAML."""
    ic = IntonationClause()
    def gi(k, d):
        v = data.get(k)
        return int(v) if v is not None else d

    ic.pre_head_start = gi("preHeadStart", ic.pre_head_start)
    ic.pre_head_end = gi("preHeadEnd", ic.pre_head_end)
    ic.head_extend_from = gi("headExtendFrom", ic.head_extend_from)
    ic.head_start = gi("headStart", ic.head_start)
    ic.head_end = gi("headEnd", ic.head_end)
    ic.head_stress_end_delta = gi("headStressEndDelta", ic.head_stress_end_delta)
    ic.head_unstressed_run_start_delta = gi("headUnstressedRunStartDelta", ic.head_unstressed_run_start_delta)
    ic.head_unstressed_run_end_delta = gi("headUnstressedRunEndDelta", ic.head_unstressed_run_end_delta)
    ic.nucleus0_start = gi("nucleus0Start", ic.nucleus0_start)
    ic.nucleus0_end = gi("nucleus0End", ic.nucleus0_end)
    ic.nucleus_start = gi("nucleusStart", ic.nucleus_start)
    ic.nucleus_end = gi("nucleusEnd", ic.nucleus_end)
    ic.tail_start = gi("tailStart", ic.tail_start)
    ic.tail_end = gi("tailEnd", ic.tail_end)

    if "headSteps" in data and isinstance(data["headSteps"], list):
        ic.head_steps = [int(x) for x in data["headSteps"]]

    return ic


def _parse_replacement(data: dict) -> Optional[ReplacementRule]:
    """Parse a single replacement rule."""
    from_str = data.get("from")
    to_val = data.get("to")
    if from_str is None or to_val is None:
        return None
    to_list = to_val if isinstance(to_val, list) else [str(to_val)]
    to_list = [str(x) for x in to_list]
    when = RuleWhen()
    if "when" in data and isinstance(data["when"], dict):
        w = data["when"]
        when.at_word_start = _parse_bool(w.get("atWordStart", False))
        when.at_word_end = _parse_bool(w.get("atWordEnd", False))
        when.before_class = str(w.get("beforeClass", ""))
        when.after_class = str(w.get("afterClass", ""))
        when.not_before_class = str(w.get("notBeforeClass", ""))
        when.not_after_class = str(w.get("notAfterClass", ""))
    return ReplacementRule(from_str=str(from_str), to_list=to_list, when=when)


def _parse_transform(data: dict) -> Optional[TransformRule]:
    """Parse a single transform rule."""
    tr = TransformRule()
    # Accept either top-level keys or nested 'match:' map
    match_data = data.get("match", data) if isinstance(data.get("match"), dict) else data

    flag_map = {
        "isVowel": "is_vowel", "isVoiced": "is_voiced", "isStop": "is_stop",
        "isAfricate": "is_affricate", "isNasal": "is_nasal", "isLiquid": "is_liquid",
        "isSemivowel": "is_semivowel", "isTap": "is_tap", "isTrill": "is_trill",
        "isFricativeLike": "is_fricative_like",
    }
    for yaml_key, py_attr in flag_map.items():
        if yaml_key in match_data:
            setattr(tr, py_attr, 1 if _parse_bool(match_data[yaml_key]) else 0)

    def parse_field_ops(key):
        ops = {}
        if key in data and isinstance(data[key], dict):
            for fn, v in data[key].items():
                if fn in FIELD_ID:
                    try:
                        ops[FIELD_ID[fn]] = float(v)
                    except (ValueError, TypeError):
                        pass
        return ops

    tr.set_ops = parse_field_ops("set")
    tr.scale_ops = parse_field_ops("scale")
    tr.add_ops = parse_field_ops("add")
    return tr


# =============================================================================
# Merge helpers (used by auto-generated _merge_settings)
# =============================================================================

def _gn_from(d: dict, key: str, default: float) -> float:
    """Get number from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    try:
        return float(v)
    except (ValueError, TypeError):
        return default


def _gb_from(d: dict, key: str, default: bool) -> bool:
    """Get bool from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    return _parse_bool(v)


def _gs_from(d: dict, key: str, default: str) -> str:
    """Get string from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    return str(v)


def _gsl_from(d: dict, key: str, default: List[str]) -> List[str]:
    """Get string list from nested dict."""
    v = d.get(key)
    if v is None:
        return default
    if isinstance(v, list):
        return [str(x) for x in v]
    if isinstance(v, str):
        return [s.strip() for s in v.split(",") if s.strip()]
    return default


# =============================================================================
# Settings merge (auto-generated from pack.cpp mergeSettings)
# =============================================================================

def _merge_settings(lp: LanguagePack, s: dict):
    """Merge settings section into LanguagePack.

    Auto-generated from pack.cpp mergeSettings(). Flat keys first, then
    nested blocks.
    """
    def gn(k, d):
        v = s.get(k)
        if v is None: return d
        try: return float(v)
        except (ValueError, TypeError): return d

    def gb(k, d):
        v = s.get(k)
        if v is None: return d
        return _parse_bool(v)

    def gs(k, d):
        v = s.get(k)
        if v is None: return d
        return str(v)

    # --- Flat keys (auto-generated) ---
    lp.primary_stress_div = gn("primaryStressDiv", lp.primary_stress_div)
    lp.secondary_stress_div = gn("secondaryStressDiv", lp.secondary_stress_div)
    lp.voice_profile_name = gs("voiceProfileName", lp.voice_profile_name)
    lp.legacy_pitch_inflection_scale = gn("legacyPitchInflectionScale", lp.legacy_pitch_inflection_scale)
    lp.fujisaki_phrase_amp = gn("fujisakiPhraseAmp", lp.fujisaki_phrase_amp)
    lp.fujisaki_primary_accent_amp = gn("fujisakiPrimaryAccentAmp", lp.fujisaki_primary_accent_amp)
    lp.fujisaki_secondary_accent_amp = gn("fujisakiSecondaryAccentAmp", lp.fujisaki_secondary_accent_amp)
    lp.fujisaki_accent_mode = gs("fujisakiAccentMode", lp.fujisaki_accent_mode)
    lp.fujisaki_phrase_len = gn("fujisakiPhraseLen", lp.fujisaki_phrase_len)
    lp.fujisaki_accent_len = gn("fujisakiAccentLen", lp.fujisaki_accent_len)
    lp.fujisaki_accent_dur = gn("fujisakiAccentDur", lp.fujisaki_accent_dur)
    lp.fujisaki_declination_scale = gn("fujisakiDeclinationScale", lp.fujisaki_declination_scale)
    lp.fujisaki_declination_max = gn("fujisakiDeclinationMax", lp.fujisaki_declination_max)
    lp.fujisaki_declination_post_floor = gn("fujisakiDeclinationPostFloor", lp.fujisaki_declination_post_floor)
    lp.post_stop_aspiration_enabled = gb("postStopAspirationEnabled", lp.post_stop_aspiration_enabled)
    lp.stop_closure_mode = gs("stopClosureMode", lp.stop_closure_mode)
    lp.stop_closure_cluster_gaps_enabled = gb("stopClosureClusterGapsEnabled", lp.stop_closure_cluster_gaps_enabled)
    lp.stop_closure_after_nasals_enabled = gb("stopClosureAfterNasalsEnabled", lp.stop_closure_after_nasals_enabled)
    lp.stop_closure_vowel_gap_ms = gn("stopClosureVowelGapMs", lp.stop_closure_vowel_gap_ms)
    lp.stop_closure_vowel_fade_ms = gn("stopClosureVowelFadeMs", lp.stop_closure_vowel_fade_ms)
    lp.stop_closure_cluster_gap_ms = gn("stopClosureClusterGapMs", lp.stop_closure_cluster_gap_ms)
    lp.stop_closure_cluster_fade_ms = gn("stopClosureClusterFadeMs", lp.stop_closure_cluster_fade_ms)
    lp.stop_closure_word_boundary_cluster_gap_ms = gn("stopClosureWordBoundaryClusterGapMs", lp.stop_closure_word_boundary_cluster_gap_ms)
    lp.stop_closure_word_boundary_cluster_fade_ms = gn("stopClosureWordBoundaryClusterFadeMs", lp.stop_closure_word_boundary_cluster_fade_ms)
    lp.segment_boundary_gap_ms = gn("segmentBoundaryGapMs", lp.segment_boundary_gap_ms)
    lp.segment_boundary_fade_ms = gn("segmentBoundaryFadeMs", lp.segment_boundary_fade_ms)
    lp.segment_boundary_skip_vowel_to_vowel = gb("segmentBoundarySkipVowelToVowel", lp.segment_boundary_skip_vowel_to_vowel)
    lp.segment_boundary_skip_vowel_to_liquid = gb("segmentBoundarySkipVowelToLiquid", lp.segment_boundary_skip_vowel_to_liquid)
    lp.single_word_tuning_enabled = gb("singleWordTuningEnabled", lp.single_word_tuning_enabled)
    lp.single_word_final_hold_ms = gn("singleWordFinalHoldMs", lp.single_word_final_hold_ms)
    lp.single_word_final_liquid_hold_scale = gn("singleWordFinalLiquidHoldScale", lp.single_word_final_liquid_hold_scale)
    lp.single_word_final_fade_ms = gn("singleWordFinalFadeMs", lp.single_word_final_fade_ms)
    lp.single_word_clause_type_override_comma_only = gb("singleWordClauseTypeOverrideCommaOnly", lp.single_word_clause_type_override_comma_only)
    lp.auto_tie_diphthongs = gb("autoTieDiphthongs", lp.auto_tie_diphthongs)
    lp.auto_diphthong_offglide_to_semivowel = gb("autoDiphthongOffglideToSemivowel", lp.auto_diphthong_offglide_to_semivowel)
    lp.semivowel_offglide_scale = gn("semivowelOffglideScale", lp.semivowel_offglide_scale)
    lp.trill_modulation_ms = gn("trillModulationMs", lp.trill_modulation_ms)
    lp.trill_modulation_fade_ms = gn("trillModulationFadeMs", lp.trill_modulation_fade_ms)
    lp.stressed_vowel_hiatus_gap_ms = gn("stressedVowelHiatusGapMs", lp.stressed_vowel_hiatus_gap_ms)
    lp.stressed_vowel_hiatus_fade_ms = gn("stressedVowelHiatusFadeMs", lp.stressed_vowel_hiatus_fade_ms)
    lp.lengthened_scale = gn("lengthenedScale", lp.lengthened_scale)
    lp.lengthened_scale_hu = gn("lengthenedScaleHu", lp.lengthened_scale_hu)
    lp.apply_lengthened_scale_to_vowels_only = gb("applyLengthenedScaleToVowelsOnly", lp.apply_lengthened_scale_to_vowels_only)
    lp.lengthened_vowel_final_coda_scale = gn("lengthenedVowelFinalCodaScale", lp.lengthened_vowel_final_coda_scale)
    lp.coarticulation_enabled = gb("coarticulationEnabled", lp.coarticulation_enabled)
    lp.coarticulation_strength = gn("coarticulationStrength", lp.coarticulation_strength)
    lp.coarticulation_transition_extent = gn("coarticulationTransitionExtent", lp.coarticulation_transition_extent)
    lp.coarticulation_fade_into_consonants = gb("coarticulationFadeIntoConsonants", lp.coarticulation_fade_into_consonants)
    lp.coarticulation_word_initial_fade_scale = gn("coarticulationWordInitialFadeScale", lp.coarticulation_word_initial_fade_scale)
    lp.coarticulation_graduated = gb("coarticulationGraduated", lp.coarticulation_graduated)
    lp.coarticulation_adjacency_max_consonants = gn("coarticulationAdjacencyMaxConsonants", lp.coarticulation_adjacency_max_consonants)
    lp.coarticulation_labial_f2_locus = gn("coarticulationLabialF2Locus", lp.coarticulation_labial_f2_locus)
    lp.coarticulation_alveolar_f2_locus = gn("coarticulationAlveolarF2Locus", lp.coarticulation_alveolar_f2_locus)
    lp.coarticulation_velar_f2_locus = gn("coarticulationVelarF2Locus", lp.coarticulation_velar_f2_locus)
    lp.coarticulation_mitalk_k = gn("coarticulationMitalkK", lp.coarticulation_mitalk_k)
    lp.coarticulation_f1_scale = gn("coarticulationF1Scale", lp.coarticulation_f1_scale)
    lp.coarticulation_f2_scale = gn("coarticulationF2Scale", lp.coarticulation_f2_scale)
    lp.coarticulation_f3_scale = gn("coarticulationF3Scale", lp.coarticulation_f3_scale)
    lp.coarticulation_alveolar_back_vowel_enabled = gb("coarticulationAlveolarBackVowelEnabled", lp.coarticulation_alveolar_back_vowel_enabled)
    lp.coarticulation_back_vowel_f2_threshold = gn("coarticulationBackVowelF2Threshold", lp.coarticulation_back_vowel_f2_threshold)
    lp.coarticulation_alveolar_back_vowel_strength_boost = gn("coarticulationAlveolarBackVowelStrengthBoost", lp.coarticulation_alveolar_back_vowel_strength_boost)
    lp.coarticulation_labialized_fricative_fronting_enabled = gb("coarticulationLabializedFricativeFrontingEnabled", lp.coarticulation_labialized_fricative_fronting_enabled)
    lp.coarticulation_labialized_fricative_f2_pull = gn("coarticulationLabializedFricativeF2Pull", lp.coarticulation_labialized_fricative_f2_pull)
    lp.coarticulation_velar_pinch_enabled = gb("coarticulationVelarPinchEnabled", lp.coarticulation_velar_pinch_enabled)
    lp.coarticulation_velar_pinch_threshold = gn("coarticulationVelarPinchThreshold", lp.coarticulation_velar_pinch_threshold)
    lp.coarticulation_velar_pinch_f2_scale = gn("coarticulationVelarPinchF2Scale", lp.coarticulation_velar_pinch_f2_scale)
    lp.coarticulation_velar_pinch_f3 = gn("coarticulationVelarPinchF3", lp.coarticulation_velar_pinch_f3)
    lp.boundary_smoothing_enabled = gb("boundarySmoothingEnabled", lp.boundary_smoothing_enabled)
    lp.boundary_smoothing_vowel_to_stop_fade_ms = gn("boundarySmoothingVowelToStopFadeMs", lp.boundary_smoothing_vowel_to_stop_fade_ms)
    lp.boundary_smoothing_stop_to_vowel_fade_ms = gn("boundarySmoothingStopToVowelFadeMs", lp.boundary_smoothing_stop_to_vowel_fade_ms)
    lp.boundary_smoothing_vowel_to_fric_fade_ms = gn("boundarySmoothingVowelToFricFadeMs", lp.boundary_smoothing_vowel_to_fric_fade_ms)
    lp.trajectory_limit_enabled = gb("trajectoryLimitEnabled", lp.trajectory_limit_enabled)
    lp.trajectory_limit_window_ms = gn("trajectoryLimitWindowMs", lp.trajectory_limit_window_ms)
    lp.trajectory_limit_apply_across_word_boundary = gb("trajectoryLimitApplyAcrossWordBoundary", lp.trajectory_limit_apply_across_word_boundary)
    lp.liquid_dynamics_enabled = gb("liquidDynamicsEnabled", lp.liquid_dynamics_enabled)
    lp.liquid_dynamics_lateral_onglide_f1_delta = gn("liquidDynamicsLateralOnglideF1Delta", lp.liquid_dynamics_lateral_onglide_f1_delta)
    lp.liquid_dynamics_lateral_onglide_f2_delta = gn("liquidDynamicsLateralOnglideF2Delta", lp.liquid_dynamics_lateral_onglide_f2_delta)
    lp.liquid_dynamics_lateral_onglide_duration_pct = gn("liquidDynamicsLateralOnglideDurationPct", lp.liquid_dynamics_lateral_onglide_duration_pct)
    lp.liquid_dynamics_rhotic_f3_dip_enabled = gb("liquidDynamicsRhoticF3DipEnabled", lp.liquid_dynamics_rhotic_f3_dip_enabled)
    lp.liquid_dynamics_rhotic_f3_minimum = gn("liquidDynamicsRhoticF3Minimum", lp.liquid_dynamics_rhotic_f3_minimum)
    lp.liquid_dynamics_rhotic_f3_dip_duration_pct = gn("liquidDynamicsRhoticF3DipDurationPct", lp.liquid_dynamics_rhotic_f3_dip_duration_pct)
    lp.liquid_dynamics_labial_glide_transition_enabled = gb("liquidDynamicsLabialGlideTransitionEnabled", lp.liquid_dynamics_labial_glide_transition_enabled)
    lp.liquid_dynamics_labial_glide_start_f1 = gn("liquidDynamicsLabialGlideStartF1", lp.liquid_dynamics_labial_glide_start_f1)
    lp.liquid_dynamics_labial_glide_start_f2 = gn("liquidDynamicsLabialGlideStartF2", lp.liquid_dynamics_labial_glide_start_f2)
    lp.liquid_dynamics_labial_glide_transition_pct = gn("liquidDynamicsLabialGlideTransitionPct", lp.liquid_dynamics_labial_glide_transition_pct)
    lp.phrase_final_lengthening_enabled = gb("phraseFinalLengtheningEnabled", lp.phrase_final_lengthening_enabled)
    lp.phrase_final_lengthening_final_syllable_scale = gn("phraseFinalLengtheningFinalSyllableScale", lp.phrase_final_lengthening_final_syllable_scale)
    lp.phrase_final_lengthening_penultimate_syllable_scale = gn("phraseFinalLengtheningPenultimateSyllableScale", lp.phrase_final_lengthening_penultimate_syllable_scale)
    lp.phrase_final_lengthening_statement_scale = gn("phraseFinalLengtheningStatementScale", lp.phrase_final_lengthening_statement_scale)
    lp.phrase_final_lengthening_question_scale = gn("phraseFinalLengtheningQuestionScale", lp.phrase_final_lengthening_question_scale)
    lp.phrase_final_lengthening_nucleus_only_mode = gb("phraseFinalLengtheningNucleusOnlyMode", lp.phrase_final_lengthening_nucleus_only_mode)
    lp.microprosody_enabled = gb("microprosodyEnabled", lp.microprosody_enabled)
    lp.microprosody_voiceless_f0_raise_enabled = gb("microprosodyVoicelessF0RaiseEnabled", lp.microprosody_voiceless_f0_raise_enabled)
    lp.microprosody_voiceless_f0_raise_hz = gn("microprosodyVoicelessF0RaiseHz", lp.microprosody_voiceless_f0_raise_hz)
    lp.microprosody_voiceless_f0_raise_end_hz = gn("microprosodyVoicelessF0RaiseEndHz", lp.microprosody_voiceless_f0_raise_end_hz)
    lp.microprosody_voiced_f0_lower_enabled = gb("microprosodyVoicedF0LowerEnabled", lp.microprosody_voiced_f0_lower_enabled)
    lp.microprosody_voiced_f0_lower_hz = gn("microprosodyVoicedF0LowerHz", lp.microprosody_voiced_f0_lower_hz)
    lp.microprosody_min_vowel_ms = gn("microprosodyMinVowelMs", lp.microprosody_min_vowel_ms)
    lp.rate_reduction_enabled = gb("rateReductionEnabled", lp.rate_reduction_enabled)
    lp.rate_reduction_schwa_reduction_threshold = gn("rateReductionSchwaReductionThreshold", lp.rate_reduction_schwa_reduction_threshold)
    lp.rate_reduction_schwa_min_duration_ms = gn("rateReductionSchwaMinDurationMs", lp.rate_reduction_schwa_min_duration_ms)
    lp.rate_reduction_schwa_scale = gn("rateReductionSchwaScale", lp.rate_reduction_schwa_scale)
    lp.word_final_schwa_reduction_enabled = gb("wordFinalSchwaReductionEnabled", lp.word_final_schwa_reduction_enabled)
    lp.word_final_schwa_scale = gn("wordFinalSchwaScale", lp.word_final_schwa_scale)
    lp.word_final_schwa_min_duration_ms = gn("wordFinalSchwaMinDurationMs", lp.word_final_schwa_min_duration_ms)
    lp.nasalization_anticipatory_enabled = gb("nasalizationAnticipatoryEnabled", lp.nasalization_anticipatory_enabled)
    lp.nasalization_anticipatory_amplitude = gn("nasalizationAnticipatoryAmplitude", lp.nasalization_anticipatory_amplitude)
    lp.nasalization_anticipatory_blend = gn("nasalizationAnticipatoryBlend", lp.nasalization_anticipatory_blend)
    lp.positional_allophones_enabled = gb("positionalAllophonesEnabled", lp.positional_allophones_enabled)
    lp.length_contrast_enabled = gb("lengthContrastEnabled", lp.length_contrast_enabled)
    lp.length_contrast_short_vowel_ceiling_ms = gn("lengthContrastShortVowelCeilingMs", lp.length_contrast_short_vowel_ceiling_ms)
    lp.length_contrast_long_vowel_floor_ms = gn("lengthContrastLongVowelFloorMs", lp.length_contrast_long_vowel_floor_ms)
    lp.length_contrast_geminate_closure_scale = gn("lengthContrastGeminateClosureScale", lp.length_contrast_geminate_closure_scale)
    lp.length_contrast_geminate_release_scale = gn("lengthContrastGeminateReleaseScale", lp.length_contrast_geminate_release_scale)
    lp.length_contrast_pre_geminate_vowel_scale = gn("lengthContrastPreGeminateVowelScale", lp.length_contrast_pre_geminate_vowel_scale)
    lp.positional_allophones_stop_aspiration_word_initial_stressed = gn("positionalAllophonesStopAspirationWordInitialStressed", lp.positional_allophones_stop_aspiration_word_initial_stressed)
    lp.positional_allophones_stop_aspiration_word_initial = gn("positionalAllophonesStopAspirationWordInitial", lp.positional_allophones_stop_aspiration_word_initial)
    lp.positional_allophones_stop_aspiration_intervocalic = gn("positionalAllophonesStopAspirationIntervocalic", lp.positional_allophones_stop_aspiration_intervocalic)
    lp.positional_allophones_stop_aspiration_word_final = gn("positionalAllophonesStopAspirationWordFinal", lp.positional_allophones_stop_aspiration_word_final)
    lp.positional_allophones_lateral_darkness_pre_vocalic = gn("positionalAllophonesLateralDarknessPreVocalic", lp.positional_allophones_lateral_darkness_pre_vocalic)
    lp.positional_allophones_lateral_darkness_post_vocalic = gn("positionalAllophonesLateralDarknessPostVocalic", lp.positional_allophones_lateral_darkness_post_vocalic)
    lp.positional_allophones_lateral_darkness_syllabic = gn("positionalAllophonesLateralDarknessSyllabic", lp.positional_allophones_lateral_darkness_syllabic)
    lp.positional_allophones_lateral_dark_f2_target_hz = gn("positionalAllophonesLateralDarkF2TargetHz", lp.positional_allophones_lateral_dark_f2_target_hz)
    lp.positional_allophones_glottal_reinforcement_enabled = gb("positionalAllophonesGlottalReinforcementEnabled", lp.positional_allophones_glottal_reinforcement_enabled)
    lp.positional_allophones_glottal_reinforcement_duration_ms = gn("positionalAllophonesGlottalReinforcementDurationMs", lp.positional_allophones_glottal_reinforcement_duration_ms)
    lp.hu_short_a_vowel_enabled = gb("huShortAVowelEnabled", lp.hu_short_a_vowel_enabled)
    lp.hu_short_a_vowel_scale = gn("huShortAVowelScale", lp.hu_short_a_vowel_scale)
    lp.english_long_u_shorten_enabled = gb("englishLongUShortenEnabled", lp.english_long_u_shorten_enabled)
    lp.english_long_u_word_final_scale = gn("englishLongUWordFinalScale", lp.english_long_u_word_final_scale)
    lp.default_pre_formant_gain = gn("defaultPreFormantGain", lp.default_pre_formant_gain)
    lp.default_output_gain = gn("defaultOutputGain", lp.default_output_gain)
    lp.default_vibrato_pitch_offset = gn("defaultVibratoPitchOffset", lp.default_vibrato_pitch_offset)
    lp.default_vibrato_speed = gn("defaultVibratoSpeed", lp.default_vibrato_speed)
    lp.default_voice_turbulence_amplitude = gn("defaultVoiceTurbulenceAmplitude", lp.default_voice_turbulence_amplitude)
    lp.default_glottal_open_quotient = gn("defaultGlottalOpenQuotient", lp.default_glottal_open_quotient)
    lp.strip_allophone_digits = gb("stripAllophoneDigits", lp.strip_allophone_digits)
    lp.strip_hyphen = gb("stripHyphen", lp.strip_hyphen)
    lp.tonal = gb("tonal", lp.tonal)
    lp.tone_digits_enabled = gb("toneDigitsEnabled", lp.tone_digits_enabled)
    lp.tone_contours_absolute = gb("toneContoursAbsolute", lp.tone_contours_absolute)

    # --- Special: legacyPitchMode string/bool hybrid ---
    raw = s.get("legacyPitchMode")
    if raw is not None:
        raw_str = str(raw).lower()
        if raw_str in ("true", "1"):
            lp.legacy_pitch_mode = "legacy"
        elif raw_str in ("false", "0"):
            lp.legacy_pitch_mode = "espeak_style"
        else:
            lp.legacy_pitch_mode = str(raw)

    # --- Special: postStopAspirationPhoneme (stored as plain string) ---
    v = s.get("postStopAspirationPhoneme")
    if v is not None:
        lp.post_stop_aspiration_phoneme = str(v)

    # --- Special: singleWordClauseTypeOverride (single char) ---
    v = s.get("singleWordClauseTypeOverride")
    if v is not None:
        sv = str(v)
        lp.single_word_clause_type_override = sv[0] if sv else ''

    # --- Special: spellingDiphthongMode (validated enum) ---
    v = s.get("spellingDiphthongMode")
    if v is not None:
        m = str(v).lower()
        if m in ("none", "monophthong"):
            lp.spelling_diphthong_mode = m

    # --- Special: toneContoursMode -> toneContoursAbsolute ---
    v = s.get("toneContoursMode")
    if v is not None:
        m = str(v).lower()
        if m == "relative":
            lp.tone_contours_absolute = False
        elif m == "absolute":
            lp.tone_contours_absolute = True

    # --- Special: trajectoryLimit flat-key parsing ---
    # trajectoryLimitApplyTo: "[cf2, cf3]" or "cf2, cf3"
    v = s.get("trajectoryLimitApplyTo")
    if v is not None:
        cleaned = str(v).replace("[", "").replace("]", "")
        mask = 0
        for part in cleaned.split(","):
            fn = part.strip()
            if fn in FIELD_ID:
                mask |= (1 << FIELD_ID[fn])
        if mask:
            lp.trajectory_limit_apply_mask = mask

    # trajectoryLimitMaxHzPerMs flat keys
    for suffix, fid_name in [("Cf2", "cf2"), ("Cf3", "cf3"), ("Pf2", "pf2"), ("Pf3", "pf3")]:
        v = s.get(f"trajectoryLimitMaxHzPerMs{suffix}")
        if v is not None:
            try:
                fv = float(v)
                if fv > 0.0:
                    lp.trajectory_limit_max_hz_per_ms[FIELD_ID[fid_name]] = fv
            except (ValueError, TypeError):
                pass

    # --- Nested blocks (auto-generated) ---

    if "boundarySmoothing" in s and isinstance(s["boundarySmoothing"], dict):
        _bs = s["boundarySmoothing"]
        lp.boundary_smoothing_enabled = _gb_from(_bs, "enabled", lp.boundary_smoothing_enabled)
        lp.boundary_smoothing_vowel_to_stop_fade_ms = _gn_from(_bs, "vowelToStopFadeMs", lp.boundary_smoothing_vowel_to_stop_fade_ms)
        lp.boundary_smoothing_stop_to_vowel_fade_ms = _gn_from(_bs, "stopToVowelFadeMs", lp.boundary_smoothing_stop_to_vowel_fade_ms)
        lp.boundary_smoothing_vowel_to_fric_fade_ms = _gn_from(_bs, "vowelToFricFadeMs", lp.boundary_smoothing_vowel_to_fric_fade_ms)

    if "trajectoryLimit" in s and isinstance(s["trajectoryLimit"], dict):
        _tl = s["trajectoryLimit"]
        lp.trajectory_limit_enabled = _gb_from(_tl, "enabled", lp.trajectory_limit_enabled)
        lp.trajectory_limit_window_ms = _gn_from(_tl, "windowMs", lp.trajectory_limit_window_ms)
        lp.trajectory_limit_apply_across_word_boundary = _gb_from(_tl, "applyAcrossWordBoundary", lp.trajectory_limit_apply_across_word_boundary)
        if "maxHzPerMs" in _tl and isinstance(_tl["maxHzPerMs"], dict):
            _mh = _tl["maxHzPerMs"]

    if "liquidDynamics" in s and isinstance(s["liquidDynamics"], dict):
        _ld = s["liquidDynamics"]
        lp.liquid_dynamics_enabled = _gb_from(_ld, "enabled", lp.liquid_dynamics_enabled)
        if "lateralOnglide" in _ld and isinstance(_ld["lateralOnglide"], dict):
            _lo = _ld["lateralOnglide"]
            lp.liquid_dynamics_lateral_onglide_f1_delta = _gn_from(_lo, "f1Delta", lp.liquid_dynamics_lateral_onglide_f1_delta)
            lp.liquid_dynamics_lateral_onglide_f2_delta = _gn_from(_lo, "f2Delta", lp.liquid_dynamics_lateral_onglide_f2_delta)
            lp.liquid_dynamics_lateral_onglide_duration_pct = _gn_from(_lo, "durationPct", lp.liquid_dynamics_lateral_onglide_duration_pct)
        if "rhoticF3Dip" in _ld and isinstance(_ld["rhoticF3Dip"], dict):
            _rd = _ld["rhoticF3Dip"]
            lp.liquid_dynamics_rhotic_f3_dip_enabled = _gb_from(_rd, "enabled", lp.liquid_dynamics_rhotic_f3_dip_enabled)
            lp.liquid_dynamics_rhotic_f3_minimum = _gn_from(_rd, "f3Minimum", lp.liquid_dynamics_rhotic_f3_minimum)
            lp.liquid_dynamics_rhotic_f3_dip_duration_pct = _gn_from(_rd, "dipDurationPct", lp.liquid_dynamics_rhotic_f3_dip_duration_pct)
        if "labialGlideTransition" in _ld and isinstance(_ld["labialGlideTransition"], dict):
            _wg = _ld["labialGlideTransition"]
            lp.liquid_dynamics_labial_glide_transition_enabled = _gb_from(_wg, "enabled", lp.liquid_dynamics_labial_glide_transition_enabled)
            lp.liquid_dynamics_labial_glide_start_f1 = _gn_from(_wg, "startF1", lp.liquid_dynamics_labial_glide_start_f1)
            lp.liquid_dynamics_labial_glide_start_f2 = _gn_from(_wg, "startF2", lp.liquid_dynamics_labial_glide_start_f2)
            lp.liquid_dynamics_labial_glide_transition_pct = _gn_from(_wg, "transitionPct", lp.liquid_dynamics_labial_glide_transition_pct)

    if "lengthContrast" in s and isinstance(s["lengthContrast"], dict):
        _lc = s["lengthContrast"]
        lp.length_contrast_enabled = _gb_from(_lc, "enabled", lp.length_contrast_enabled)
        lp.length_contrast_short_vowel_ceiling_ms = _gn_from(_lc, "shortVowelCeiling", lp.length_contrast_short_vowel_ceiling_ms)
        lp.length_contrast_long_vowel_floor_ms = _gn_from(_lc, "longVowelFloor", lp.length_contrast_long_vowel_floor_ms)
        lp.length_contrast_geminate_closure_scale = _gn_from(_lc, "geminateClosureScale", lp.length_contrast_geminate_closure_scale)
        lp.length_contrast_geminate_release_scale = _gn_from(_lc, "geminateReleaseScale", lp.length_contrast_geminate_release_scale)
        lp.length_contrast_pre_geminate_vowel_scale = _gn_from(_lc, "preGeminateVowelScale", lp.length_contrast_pre_geminate_vowel_scale)

    if "positionalAllophones" in s and isinstance(s["positionalAllophones"], dict):
        _pa = s["positionalAllophones"]
        lp.positional_allophones_enabled = _gb_from(_pa, "enabled", lp.positional_allophones_enabled)
        lp.positional_allophones_lateral_dark_f2_target_hz = _gn_from(_pa, "lateralDarkF2Target", lp.positional_allophones_lateral_dark_f2_target_hz)
        lp.positional_allophones_glottal_reinforcement_duration_ms = _gn_from(_pa, "glottalReinforcementDurationMs", lp.positional_allophones_glottal_reinforcement_duration_ms)
        if "stopAspiration" in _pa and isinstance(_pa["stopAspiration"], dict):
            _sa = _pa["stopAspiration"]
            lp.positional_allophones_stop_aspiration_word_initial_stressed = _gn_from(_sa, "wordInitialStressed", lp.positional_allophones_stop_aspiration_word_initial_stressed)
            lp.positional_allophones_stop_aspiration_word_initial = _gn_from(_sa, "wordInitial", lp.positional_allophones_stop_aspiration_word_initial)
            lp.positional_allophones_stop_aspiration_intervocalic = _gn_from(_sa, "intervocalic", lp.positional_allophones_stop_aspiration_intervocalic)
            lp.positional_allophones_stop_aspiration_word_final = _gn_from(_sa, "wordFinal", lp.positional_allophones_stop_aspiration_word_final)
        if "lateralDarkness" in _pa and isinstance(_pa["lateralDarkness"], dict):
            _ld = _pa["lateralDarkness"]
            lp.positional_allophones_lateral_darkness_pre_vocalic = _gn_from(_ld, "preVocalic", lp.positional_allophones_lateral_darkness_pre_vocalic)
            lp.positional_allophones_lateral_darkness_post_vocalic = _gn_from(_ld, "postVocalic", lp.positional_allophones_lateral_darkness_post_vocalic)
            lp.positional_allophones_lateral_darkness_syllabic = _gn_from(_ld, "syllabic", lp.positional_allophones_lateral_darkness_syllabic)
        if "glottalReinforcement" in _pa and isinstance(_pa["glottalReinforcement"], dict):
            _gr = _pa["glottalReinforcement"]
            lp.positional_allophones_glottal_reinforcement_enabled = _gb_from(_gr, "enabled", lp.positional_allophones_glottal_reinforcement_enabled)
            lp.positional_allophones_glottal_reinforcement_contexts = _gsl_from(_gr, "contexts", lp.positional_allophones_glottal_reinforcement_contexts)

    # --- Special nested: trajectoryLimit maxHzPerMs map + applyTo list ---
    if "trajectoryLimit" in s and isinstance(s["trajectoryLimit"], dict):
        _tl = s["trajectoryLimit"]
        if "applyTo" in _tl and isinstance(_tl["applyTo"], list):
            mask = 0
            for fn in _tl["applyTo"]:
                if str(fn) in FIELD_ID:
                    mask |= (1 << FIELD_ID[str(fn)])
            if mask:
                lp.trajectory_limit_apply_mask = mask
        if "maxHzPerMs" in _tl and isinstance(_tl["maxHzPerMs"], dict):
            for fn, v in _tl["maxHzPerMs"].items():
                if fn in FIELD_ID:
                    try:
                        lp.trajectory_limit_max_hz_per_ms[FIELD_ID[fn]] = float(v)
                    except (ValueError, TypeError):
                        pass


# =============================================================================
# Normalization / Intonation / Tone merge
# --- MANUAL ---
# =============================================================================

def _merge_norm(lp: LanguagePack, n: dict):
    if "aliases" in n and isinstance(n["aliases"], dict):
        for k, v in n["aliases"].items():
            lp.aliases[str(k)] = str(v)
    if "classes" in n and isinstance(n["classes"], dict):
        for cn, items in n["classes"].items():
            if isinstance(items, list):
                lp.classes[str(cn)] = [str(x) for x in items]
    if "preReplacements" in n and isinstance(n["preReplacements"], list):
        for item in n["preReplacements"]:
            if isinstance(item, dict):
                r = _parse_replacement(item)
                if r:
                    lp.pre_replacements.append(r)
    if "replacements" in n and isinstance(n["replacements"], list):
        for item in n["replacements"]:
            if isinstance(item, dict):
                r = _parse_replacement(item)
                if r:
                    lp.replacements.append(r)
    if "stripAllophoneDigits" in n:
        lp.strip_allophone_digits = _parse_bool(n["stripAllophoneDigits"])
    if "stripHyphen" in n:
        lp.strip_hyphen = _parse_bool(n["stripHyphen"])


def _merge_intonation(lp: LanguagePack, data: dict):
    for k, v in data.items():
        if k and k[0] in ".?!," and isinstance(v, dict):
            lp.intonation[k[0]] = _parse_intonation(v)


def _merge_tones(lp: LanguagePack, data: dict):
    for k, v in data.items():
        pts = [int(x) for x in v] if isinstance(v, list) else [int(v)] if isinstance(v, (int, float)) else []
        if pts:
            lp.tone_contours[str(k)] = pts


def _merge_transforms(lp: LanguagePack, data):
    if not isinstance(data, list):
        return
    for item in data:
        if isinstance(item, dict):
            tr = _parse_transform(item)
            if tr:
                lp.transforms.append(tr)


# =============================================================================
# Default intonation (matches applyLanguageDefaults in pack.cpp)
# --- MANUAL ---
# =============================================================================

def _apply_defaults(lp: LanguagePack):
    lp.intonation["."] = IntonationClause(46,57,4,80,50,[100,75,50,25,0,63,38,13,0],-16,-8,-5,64,8,70,18,24,8)
    lp.intonation[","] = IntonationClause(46,57,4,80,60,[100,75,50,25,0,63,38,13,0],-16,-8,-5,34,52,78,34,34,52)
    lp.intonation["?"] = IntonationClause(45,56,3,75,43,[100,75,50,20,60,35,11,0],-16,-7,0,34,68,86,21,34,68)
    lp.intonation["!"] = IntonationClause(46,57,3,90,50,[100,75,50,16,82,50,32,16],-16,-9,0,92,4,92,80,76,4)


# =============================================================================
# Main loading functions
# --- MANUAL ---
# =============================================================================

def find_packs_root(pack_dir: str) -> Path:
    p = Path(pack_dir)
    if (p / "phonemes.yaml").exists():
        return p
    if (p / "packs" / "phonemes.yaml").exists():
        return p / "packs"
    raise FileNotFoundError(f"phonemes.yaml not found under {pack_dir}")


def load_pack_set(pack_dir: str, lang_tag: str = "default") -> PackSet:
    """Load complete pack set with phonemes and merged language settings."""
    root = find_packs_root(pack_dir)
    pack = PackSet()

    # Load phonemes
    data = load_yaml_file(root / "phonemes.yaml")
    if data and "phonemes" in data:
        for k, v in data["phonemes"].items():
            if isinstance(v, dict):
                pack.phonemes[k] = _parse_phoneme(k, v)

    # Initialize language pack
    pack.lang = LanguagePack()
    pack.lang.lang_tag = lang_tag.lower().replace("_", "-")
    _apply_defaults(pack.lang)

    # Build chain: default -> base -> base-region
    chain = ["default"]
    parts = pack.lang.lang_tag.split("-")
    cur = ""
    for p in parts:
        cur = f"{cur}-{p}" if cur else p
        if cur not in chain:
            chain.append(cur)

    # Load each file in chain
    for name in chain:
        lf = root / "lang" / f"{name}.yaml"
        if lf.exists():
            data = load_yaml_file(lf)
            if not data:
                continue
            if "settings" in data:
                _merge_settings(pack.lang, data["settings"])
            if "normalization" in data:
                _merge_norm(pack.lang, data["normalization"])
            if "transforms" in data:
                _merge_transforms(pack.lang, data["transforms"])
            if "intonation" in data:
                _merge_intonation(pack.lang, data["intonation"])
            if "toneContours" in data:
                _merge_tones(pack.lang, data["toneContours"])
            if "phonemes" in data:
                for k, v in data["phonemes"].items():
                    if isinstance(v, dict):
                        pack.phonemes[k] = _parse_phoneme(k, v)

    return pack


# =============================================================================
# Utilities
# --- MANUAL ---
# =============================================================================

def format_pack_summary(pack: PackSet) -> str:
    """Return a human-readable summary of the pack."""
    lp = pack.lang
    return f"""=== Pack: {lp.lang_tag} ===
Phonemes: {len(pack.phonemes)}

Timing:
  primaryStressDiv: {lp.primary_stress_div}
  secondaryStressDiv: {lp.secondary_stress_div}
  defaultVowelDurationMs: {lp.default_vowel_duration_ms}
  defaultFadeMs: {lp.default_fade_ms}
  stopDurationMs: {lp.stop_duration_ms}

Pitch:
  legacyPitchMode: {lp.legacy_pitch_mode}
  fujisakiPhraseAmp: {lp.fujisaki_phrase_amp}
  fujisakiAccentMode: {lp.fujisaki_accent_mode}

Stop Closure:
  mode: {lp.stop_closure_mode}
  vowelGapMs: {lp.stop_closure_vowel_gap_ms}
  clusterGapMs: {lp.stop_closure_cluster_gap_ms}

Coarticulation:
  enabled: {lp.coarticulation_enabled}
  strength: {lp.coarticulation_strength}
  mitalkK: {lp.coarticulation_mitalk_k}
  labialF2Locus: {lp.coarticulation_labial_f2_locus}
  alveolarF2Locus: {lp.coarticulation_alveolar_f2_locus}
  velarF2Locus: {lp.coarticulation_velar_f2_locus}

Trajectory Limiting:
  enabled: {lp.trajectory_limit_enabled}
  windowMs: {lp.trajectory_limit_window_ms}

Defaults:
  preFormantGain: {lp.default_pre_formant_gain}
  outputGain: {lp.default_output_gain}
"""


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("Usage: python lang_pack.py <packs_dir> [lang_tag]")
        sys.exit(1)
    lang = sys.argv[2] if len(sys.argv) > 2 else "default"
    pack = load_pack_set(sys.argv[1], lang)
    print(format_pack_summary(pack))
